{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizer for Handwritten Text Synthesis GAN\n",
    "\n",
    "This model will consist of 4 major networks, following the general architecture of an GAN.\n",
    "\n",
    "1. Encoder: Produces an embedding that will be concatenated with the noise vector.\n",
    "2. Generator: Taking noise vector as input and the text embedding to produce an 128x2048 image.\n",
    "3. Discriminator: Trained alternating with generator input and ground-truth input, binary classification real or fake.\n",
    "4. Recognizer: Taking image as input, produce a vector representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/aps360/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_fidelity\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torch.nn.utils.spectral_norm import spectral_norm\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, Subset, random_split\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Grayscale, Resize, ToTensor, ToPILImage\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "from torchmetrics.text import CharErrorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (Run once only to format data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_HEIGHT = 32\n",
    "SCALE_WIDTH = SCALE_HEIGHT*16\n",
    "\n",
    "def preprocess_lines(data_root):\n",
    "    \"\"\"\n",
    "    Creates a new `.txt` file `lines_improved.txt` that will be used\n",
    "    for querying. This new `.txt` file contains all info necessary\n",
    "    for the functionality of this project.\n",
    "    \"\"\"\n",
    "\n",
    "    original_path = os.path.join(data_root, \"lines.txt\")\n",
    "    improved_path = os.path.join(data_root, \"lines_improved.txt\")\n",
    "    fi = open(improved_path, \"w\")\n",
    "\n",
    "    # Some variables for tracking\n",
    "    num_samples = 0\n",
    "    valid_samples = 0\n",
    "    \n",
    "    # Loop through \"lines.txt\"\n",
    "    with open(original_path, \"r\") as fo:\n",
    "        headers = [\"image_id\", \"image_path\", \"image_pt_path\", \"graylevel\", \"original_height\", \"original_width\", \"transcription\", \"transcription_len\"]\n",
    "\n",
    "        # First write the headers at the top of the file\n",
    "        fi.writelines(\"\\t\".join(headers) + \"\\n\")\n",
    "\n",
    "        # Skip the intro stuff\n",
    "        for line in fo.readlines():\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            # Valid lines, not the intro_text\n",
    "            line_items = line.strip().split(\" \")  # `strip()` to remove newlines\n",
    "\n",
    "            # The actual items (we extract the important ones)\n",
    "            image_id = line_items[0]\n",
    "            status = line_items[1]\n",
    "            graylevel = int(line_items[2])\n",
    "            transcription = \" \".join(line_items[8:])  # Some data has whitespace, we join string till the end\n",
    "\n",
    "            # Skip error images\n",
    "            if status == \"err\":\n",
    "                continue\n",
    "        \n",
    "            # Alphanumeric + common punctuation regex\n",
    "            # Returns None if no match\n",
    "            # 26 + 26 + 10 + 9 + 1 = 72\n",
    "            # Spaces might be included as well\n",
    "            # Punctuation include , ! ? ' \" , : ; -\n",
    "            if re.fullmatch(\"[a-zA-Z0-9.!?'\\\",:;| -]*\", transcription) is None:\n",
    "                continue\n",
    "\n",
    "            # Now we have valid transcription\n",
    "            num_samples += 1\n",
    "\n",
    "            # We get the `.png` image path\n",
    "            inp = image_id.split(\"-\")  # `inp` stands for image name parts\n",
    "            image_path_head = os.path.join(data_root, \"lines\", inp[0], f\"{inp[0]}-{inp[1]}\")\n",
    "            image_path_tail = f\"{image_id}.png\"\n",
    "            image_path = os.path.join(image_path_head, image_path_tail)\n",
    "            \n",
    "            # Read image, gets its dimensions, perform processing operations, and other stuff\n",
    "            tmp_image = cv.imread(os.path.join(image_path_head, image_path_tail), cv.IMREAD_GRAYSCALE)  # Removes the channel dimension\n",
    "            height, width = tmp_image.shape\n",
    "\n",
    "            # Scaling calculations\n",
    "            # If width * scale >= desired length (>= to be safe)\n",
    "            # Condition here to speed up overall processing time\n",
    "            if width * (SCALE_HEIGHT/height) >= SCALE_WIDTH:\n",
    "                continue\n",
    "\n",
    "            resized_tensor = process_image(tmp_image, graylevel)\n",
    "            image_pt_path = os.path.join(image_path_head, f\"{image_id}.pt\")\n",
    "            torch.save(resized_tensor, image_pt_path)\n",
    "\n",
    "            # A fully valid image\n",
    "            # Separate by underscores because `transcription` has spaces so we can't split by spaces\n",
    "            fi.writelines(f\"{image_id}\\t{image_path}\\t{image_pt_path}\\t{graylevel}\\t{height}\\t{width}\\t{transcription}\\t{len(transcription)}\\n\")\n",
    "            valid_samples += 1\n",
    "        \n",
    "        fi.close()\n",
    "    \n",
    "    print(\"# samples:\", num_samples)\n",
    "    print(\"Valid samples:\", valid_samples)\n",
    "\n",
    "\n",
    "def process_image(cv_image, graylevel):\n",
    "    \"\"\"\n",
    "    Takes in a grayscale image that OpenCV read of shape (H, W) of type uint8\n",
    "    Returns a PyTorch tensor of shape (1, 32, W'), where W' is the scaled width\n",
    "    This tensor is padded and effectively thresholded\n",
    "    \"\"\"\n",
    "\n",
    "    # Scaling factor\n",
    "    height, width = cv_image.shape\n",
    "    scale = SCALE_HEIGHT/height\n",
    "    scaled_width = int(width*scale)\n",
    "\n",
    "    # Trick here is to apply threshold before resize and padding\n",
    "    # This allows OpenCV resizing to create a cleaner output image\n",
    "    # 2nd return value is the thresholded image\n",
    "    output = cv.threshold(cv_image, graylevel, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "    # INTER_AREA recommended for sizing down\n",
    "    output = cv.resize(output, (scaled_width, SCALE_HEIGHT), interpolation=cv.INTER_AREA)\n",
    "\n",
    "    # Turn it back to a tensor and map to [0, 1]\n",
    "    output = torch.from_numpy(output).unsqueeze(0).type(torch.float32)\n",
    "    output = (output-output.min()) / (output.max()-output.min())\n",
    "    \n",
    "    # Add padding\n",
    "    _, _, resized_height = output.shape\n",
    "    padding_to_add = SCALE_WIDTH - resized_height\n",
    "    output = F.pad(output, (0, padding_to_add), value=1.0)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Uncomment this if your data isn't processed yet\n",
    "# preprocess_lines(\"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Dict (Run everytime before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted by ascii code\n",
    "valid = [\n",
    "    ' ', '!', '\"', \"'\", ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "    ':', ';', '?', \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
    "]\n",
    "# Enumerate from 1 to save space for padding\n",
    "# Reserve 0 for CTC blank\n",
    "char_to_int = {v: i for i, v in enumerate(valid, 1)}\n",
    "int_to_char = {i: v for i, v in enumerate(valid, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineDataset(Dataset):\n",
    "    def __init__(self, lines_improved_dir, ty=None):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            lines_improved_dir: path to the `lines_improved.txt` file\n",
    "            ty: type of the dataset \"txt\", \"img\" for text dataset or image dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dataframe containing the stuff in `lines_improved.txt`\n",
    "        self.lines_df = pd.read_csv(lines_improved_dir, sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "        # Class properties\n",
    "        self.ty = ty  # Type of dataset (lines, images, or both)\n",
    "        self.max_transcription_len = max(self.lines_df[\"transcription_len\"])\n",
    "\n",
    "        # Temp variables...\n",
    "        length = self.lines_df.shape[0]\n",
    "        line_datas = self.lines_df.iloc\n",
    "        ret_texts = [line_datas[i][\"transcription\"].replace('|', ' ') for i in range(length)]\n",
    "        ret_ctois = [torch.tensor([char_to_int[char] for char in ret_texts[i]]) for i in range(length)]\n",
    "\n",
    "        # ...for the important data\n",
    "        if self.ty in (\"txt\", None):  # Added this condition to speed thigns up if only text\n",
    "            self.ret_ctoi_paddeds = [F.pad(ret_ctois[i], pad=(0, self.max_transcription_len-len(ret_ctois[i])), value=0) for i in range(length)]\n",
    "        if self.ty in (\"img\", None):\n",
    "            self.ret_images = [torch.load(line_datas[i][\"image_pt_path\"]) for i in range(length)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Different type of individual loaders\n",
    "        if self.ty == \"txt\":\n",
    "            return self.ret_ctoi_paddeds[index]\n",
    "        elif self.ty == \"img\":\n",
    "            return self.ret_images[index]\n",
    "        else:\n",
    "            return self.ret_images[index], self.ret_ctoi_paddeds[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "320 10\n",
      "images\n",
      "320 10\n",
      "both\n",
      "1000 100\n"
     ]
    }
   ],
   "source": [
    "line_transcription_dataset = LineDataset(\"./data/lines_improved.txt\", ty=\"txt\")\n",
    "line_image_dataset = LineDataset(\"./data/lines_improved.txt\", ty=\"img\")\n",
    "line_dataset = LineDataset(\"./data/lines_improved.txt\")\n",
    "\n",
    "# Don't change this, we want to maintain consistent split\n",
    "torch.manual_seed(12345678)  # DO NOT REMOVE THIS LINE\n",
    "line_transcription_dataset_train, line_transcription_dataset_val = random_split(line_transcription_dataset, [0.8, 0.2])\n",
    "line_image_dataset_train, line_image_dataset_val = random_split(line_image_dataset, [0.8, 0.2])\n",
    "line_dataset_train, line_dataset_val = random_split(line_dataset, [0.8, 0.2])\n",
    "\n",
    "# To train on a small dataset\n",
    "line_transcription_dataset_train = Subset(line_transcription_dataset_train, range(64*5))\n",
    "line_transcription_dataset_val = Subset(line_transcription_dataset_val, range(10))\n",
    "\n",
    "line_image_dataset_train = Subset(line_image_dataset_train, range(64*5))\n",
    "line_image_dataset_val = Subset(line_image_dataset_val, range(10))\n",
    "\n",
    "line_dataset_train = Subset(line_dataset_train, range(1000))\n",
    "line_dataset_val = Subset(line_dataset_val, range(100))\n",
    "\n",
    "# line_transcription_dataset_train, line_transcription_dataset_val, _ = random_split(line_transcription_dataset, [0.005, 0.005, 0.99])\n",
    "# line_image_dataset_train, line_image_dataset_val, _ = random_split(line_image_dataset, [0.005, 0.005, 0.99])\n",
    "# line_dataset_train, line_dataset_val = random_split(line_dataset, [0.0025, 0.9975])\n",
    "\n",
    "print(\"lines\")\n",
    "print(len(line_transcription_dataset_train), len(line_transcription_dataset_val))\n",
    "print(\"images\")\n",
    "print(len(line_image_dataset_train), len(line_image_dataset_val))\n",
    "print(\"both\")\n",
    "print(len(line_dataset_train), len(line_dataset_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512])\n",
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([66, 61,  1,  9, 17,  1,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " 'to 19 .')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = line_dataset_train[0]\n",
    "print(image.shape)\n",
    "plt.title(\"\".join([int_to_char[int(val)] for val in label[label.nonzero()]]))\n",
    "print(image.squeeze(0).shape)\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "label, \"\".join([int_to_char[int(val)] for val in label[label.nonzero()]])\n",
    "# line_dataset.lines_df.iloc[798]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "class Recognizer(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN:\n",
    "    Input with a N x 1 x 32 x 512 image\n",
    "    Output a vector representation of the text size N x 73 x (82*2+1)\n",
    "    Purpose is to recognize the text from the image, to encourage the generator to produce images that are representations of the text\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"recognizer\"\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=8)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(4,2))\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=128)\n",
    "        #self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(4,2))\n",
    "        #self.bn6 = nn.BatchNorm2d(num_features=256)\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, num_layers=3, bidirectional=True, batch_first=True, dropout=0.5)\n",
    "        self.dense = nn.Linear(256, 73)\n",
    "        self.dense2 = nn.Linear(248, 82)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout2d(p=0.3)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img = self.bn1(self.lrelu(self.maxpool(self.conv1(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn2(self.lrelu(self.conv2(img)))\n",
    "        #print(img.shape)\n",
    "        img = self.bn3(self.lrelu(self.dropout(self.conv3(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn4(self.lrelu(self.dropout(self.conv4(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn5(self.lrelu(self.dropout(self.conv5(img))))\n",
    "        #print(img.shape)\n",
    "        # Collapse \n",
    "        img, _ = torch.max(img, dim=2)\n",
    "        #print(img.shape)\n",
    "        img = img.permute(0, 2, 1)\n",
    "        #print(img.shape)\n",
    "        img, _ = self.lstm(img)\n",
    "        #print(img.shape)\n",
    "        img = self.lrelu(self.dense(img))\n",
    "        #print(img.shape)\n",
    "        img = img.permute(0,2,1)\n",
    "        img = self.dense2(img)\n",
    "        #print(img.shape)\n",
    "        #print(img.shape)\n",
    "        return img\n",
    "        # img = torch.stack()\n",
    "        # img = self.dense(img)\n",
    "        \n",
    "    \n",
    "#recog = Recognizer()\n",
    "#a =recog(torch.randn((1, 1, 32, 512), dtype=torch.float32))\n",
    "#print(recog)\n",
    "    # TODO: http://www.tbluche.com/files/icdar17_gnn.pdf use \"big architecture\"\n",
    "#a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(device, recognizer, val_line_dataset_loader, recognizer_loss_function):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_epoch = 0\n",
    "    \n",
    "    for i, (line_image_batch, line_text_batch) in enumerate(val_line_dataset_loader, 0):\n",
    "        line_image_batch = line_image_batch.to(device) \n",
    "        line_text_batch = line_text_batch.to(device)\n",
    "        recognizer_outputs = recognizer(line_image_batch)\n",
    "        recognizer_loss = recognizer_loss_function(F.log_softmax(recognizer_outputs, 1), line_text_batch)\n",
    "        \n",
    "        total_loss += recognizer_loss.item()\n",
    "        total_epoch += 1\n",
    "        \n",
    "    loss = float(total_loss) / (i + 1)\n",
    "    \n",
    "    #print(recognizer_outputs, recognizer_outputs.shape)\n",
    "    #print(torch.argmax(recognizer_outputs, 1), torch.argmax(recognizer_outputs, 1).shape)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_recog_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of the recognizer with character error rate\n",
    "    which is based on edit distance\n",
    "\n",
    "    Params:\n",
    "        preds: a list of prediction strings\n",
    "        targets: a list of target strings\n",
    "\n",
    "    Returns:\n",
    "        An integer, the character error rate average across\n",
    "        all predictions and targets\n",
    "    \"\"\"\n",
    "\n",
    "    cer = CharErrorRate()\n",
    "    return cer(preds, target)\n",
    "\n",
    "def create_strings_from_tensor(int_tensor):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        int_tensor: A shape (N, 82) tensor where each row corresponds to\n",
    "        a integer mapping of a string. Includes padding\n",
    "    \n",
    "    Returns:\n",
    "        A list of N strings\n",
    "    \"\"\"\n",
    "\n",
    "    strings = []\n",
    "    for string_map in int_tensor:\n",
    "        strings.append(\"\".join([int_to_char[int(i)] for i in string_map[string_map != 0]]))\n",
    "    return strings\n",
    "    \n",
    "\n",
    "def get_accuracy(device, recognizer, recognizer_loader):\n",
    "\n",
    "    acc = 0\n",
    "    \n",
    "    for i, (line_image_batch, line_text_batch) in enumerate(recognizer_loader, 0):\n",
    "        line_image_batch = line_image_batch.to(device)\n",
    "        line_text_batch\n",
    "        recognizer_outputs = torch.argmax(recognizer(line_image_batch), 1)\n",
    "        recognizer_pred = create_strings_from_tensor(recognizer_outputs)\n",
    "        \n",
    "        label = create_strings_from_tensor(line_text_batch)\n",
    "        \n",
    "        acc += calculate_recog_accuracy(recognizer_pred, label)\n",
    "        \n",
    "        \n",
    "    return acc / (i+1)\n",
    "        \n",
    "    \n",
    "\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n",
    "\n",
    "def plot_training_curve(path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    \n",
    "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
    "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
    "    \n",
    "    n = len(train_loss) # number of epochs\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Train vs Validation Error\")\n",
    "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend([\"Train Error\", \"Validation Error\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(recognizer, \n",
    "              train_line_dataset, val_line_dataset, \n",
    "              batch_size=64, recognizer_lr=1e-5,\n",
    "              betas=(0, 0.999), num_epochs=30, loss_balancing_alpha=1):\n",
    "    # Note, the generator and discriminator should be spectrally normalized before training\n",
    "    # TODO: load dataloader with batch size batch_size\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device('cpu')\n",
    "    #print(device)\n",
    "    recognizer = recognizer.to(device)\n",
    "    \n",
    "    train_line_dataset_loader = DataLoader(train_line_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_line_dataset_loader = DataLoader(val_line_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #print(len(train_line_dataset_loader))\n",
    "\n",
    "    recognizer_optimizer = optim.Adam(recognizer.parameters(), lr=recognizer_lr)\n",
    "    \n",
    "    recognizer_loss_function = nn.NLLLoss()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(recognizer.parameters(), max_norm=0.5)\n",
    "    recognizer_train_losses = np.zeros(num_epochs)\n",
    "    recognizer_train_accuracies = np.zeros(num_epochs)\n",
    "    recognizer_val_losses = np.zeros(num_epochs)\n",
    "    recognizer_val_accuracies = np.zeros(num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        display_images = []\n",
    "\n",
    "        recognizer_train_loss = 0\n",
    "\n",
    "        for i, (line_image_batch, line_text_batch) in enumerate(train_line_dataset_loader):\n",
    "#             print(\"epoch\", epoch, \"batch\", i)\n",
    "#             print(\"line_image_batch.shape\", line_image_batch.shape)\n",
    "            cur_batch_size, _ = line_text_batch.shape\n",
    "            # print(line_text_batch.shape)\n",
    "\n",
    "#             print(\"line_text_batch.shape\", line_text_batch.shape)\n",
    "            test = line_text_batch[0]\n",
    "            test = test[test.nonzero()]\n",
    "            test = \"\".join([int_to_char[int(i)] for i in test])\n",
    "            line_image_batch = line_image_batch.to(device)\n",
    "            line_text_batch = line_text_batch.to(device)\n",
    "            plt.imshow(line_image_batch[0].cpu().squeeze(0), cmap='gray')\n",
    "            #print(line_text_batch, line_text_batch.shape)\n",
    "            recognizer_outputs = recognizer(line_image_batch)  # Mult factor to incentivize padding\n",
    "   \n",
    "            # print(recognizer_outputs, recognizer_outputs.shape)\n",
    "            # print(line_text_batch, line_text_batch.shape)\n",
    "#             test2 = \"\".join([int_to_char[int(i)] for i in test2])\n",
    "\n",
    "#             Refer to CTC documentation\n",
    "            #line_text_batch_pad_remove = [line_text[line_text.nonzero().squeeze(1)] for line_text in line_text_batch]  # Array of tensors\n",
    "            #target_lengths = torch.tensor([len(line_text_pad_remove) for line_text_pad_remove in line_text_batch_pad_remove])\n",
    "            #target = torch.cat(line_text_batch_pad_remove)\n",
    "            #print(target, target.shape)\n",
    "            #input_lengths = torch.full(size=(cur_batch_size,), fill_value=248)\n",
    "            recognizer_loss = recognizer_loss_function(\n",
    "                # torch.argmax(F.log_softmax(recognizer_outputs, 2), 1),\n",
    "                F.log_softmax(recognizer_outputs, 1),  # Requires number of classes to move from 2nd to 1st dimension after log_softmax\n",
    "                line_text_batch\n",
    "            )\n",
    "            test2 = recognizer_outputs[0,:,:]\n",
    "            test2 = torch.argmax(test2, dim=0)  # Removed 0 dim\n",
    "            test2 = test2[test2.nonzero()]\n",
    "            test2 = \"\".join([int_to_char[int(i)] for i in test2])\n",
    "            \n",
    "\n",
    "            recognizer_loss.backward()\n",
    "            recognizer_optimizer.step()\n",
    "            recognizer_optimizer.zero_grad()\n",
    "    \n",
    "            recognizer_train_loss += recognizer_loss.item()\n",
    "        \n",
    "        print(\"\\t\",test)\n",
    "        print(f\"_{test2}_\")\n",
    "        recognizer_train_losses[epoch] = float(recognizer_train_loss) / (i+1)\n",
    "        recognizer_val_losses[epoch] = evaluate(device, recognizer, val_line_dataset_loader, recognizer_loss_function)\n",
    "        \n",
    "        recognizer_train_accuracies[epoch] = get_accuracy(device, recognizer, train_line_dataset_loader)\n",
    "        recognizer_val_accuracies[epoch]= get_accuracy(device, recognizer, val_line_dataset_loader)\n",
    "        \n",
    "        print((\"Epoch {}: Train loss: {} | Train Accuracy: {} | \"+\n",
    "            \" Validation loss: {} | Validation Accuracy: {}\").format(\n",
    "                    epoch + 1,\n",
    "                    recognizer_train_losses[epoch],\n",
    "                    recognizer_train_accuracies[epoch],\n",
    "                    recognizer_val_losses[epoch],\n",
    "                    recognizer_val_accuracies[epoch]))\n",
    "\n",
    "        model_path = get_model_name(recognizer.name, batch_size, recognizer_lr, epoch)\n",
    "        torch.save(recognizer.state_dict(), os.path.join(\"./recognizers\", model_path))\n",
    "        model_path_const_batch = get_model_name(recognizer.name, batch_size, recognizer_lr, -1)\n",
    "\n",
    "        np.savetxt(\"./recognizers/{}_train_loss.csv\".format(model_path_const_batch), recognizer_train_losses)\n",
    "        np.savetxt(\"./recognizers/{}_val_loss.csv\".format(model_path_const_batch),  recognizer_val_losses)\n",
    "        np.savetxt(\"./recognizers/{}_train_acc.csv\".format(model_path_const_batch), recognizer_train_accuracies)\n",
    "        np.savetxt(\"./recognizers/{}_val_acc.csv\".format(model_path_const_batch), recognizer_val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_training_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_training_curve(\u001b[39m\"\u001b[39m\u001b[39m./recognizers/model_recognizer_bs4_lr0.001_epoch99\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_training_curve' is not defined"
     ]
    }
   ],
   "source": [
    "plot_training_curve(\"./recognizers/model_recognizer_bs4_lr0.001_epoch99\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Main Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Hyperparameters to Tune\n",
    "- Dimension of text embedding, we can start with 128, 256, or 512 and increase it later on.\n",
    "- Dataset of training. If the model does not converge, it is likely we will have to manually select example images that have similar writing style.\n",
    "- Learning rate\n",
    "- Balancing the effect of recognizer and discriminator\n",
    "\n",
    "- Generator Networks:\n",
    "  - ResNetUp\n",
    "    - Should the bias be False? Or can it be True?\n",
    "      - conv1 probably don't, since it is batch-normalized right after\n",
    "      - but what about conv2?\n",
    "  - Conditional Batch Norm\n",
    "  - Number of filters in each resnet block\n",
    "\n",
    "LSTM hidden layers should increase, hidden size should increase. \n",
    "- because our text is longer. \n",
    "\n",
    "- Discriminator Networks:\n",
    "  - ResNetDown\n",
    "    - Still if bias should be False?\n",
    "    - LeakyReLU slope\n",
    "  - ResNet\n",
    "    - bias?\n",
    "    - leakyReLU slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t water that is blown offshore must\n",
      "__\n",
      "Epoch 1: Train loss: 2.97427836060524 | Train Accuracy: 1.0 |  Validation loss: 2.0166094601154327 | Validation Accuracy: 1.0\n",
      "\t delicacy - sought inspiration at last from\n",
      "__\n",
      "Epoch 2: Train loss: 1.9623841270804405 | Train Accuracy: 1.0 |  Validation loss: 1.9092839658260345 | Validation Accuracy: 1.0\n",
      "\t So they proceeded to see if the coast\n",
      "__\n",
      "Epoch 3: Train loss: 1.8788625821471214 | Train Accuracy: 1.0 |  Validation loss: 1.9374063313007355 | Validation Accuracy: 1.0\n",
      "\t first two centuries ?\n",
      "__\n",
      "Epoch 4: Train loss: 1.8663739114999771 | Train Accuracy: 1.0 |  Validation loss: 1.8804213404655457 | Validation Accuracy: 1.0\n",
      "\t was being cultivated with extraordinary\n",
      "__\n",
      "Epoch 5: Train loss: 1.8549486175179482 | Train Accuracy: 0.9998605251312256 |  Validation loss: 1.785518616437912 | Validation Accuracy: 1.0\n",
      "\t Russia . Now he wants Britain to demolish her\n",
      "__\n",
      "Epoch 6: Train loss: 1.8395783379673958 | Train Accuracy: 0.97761070728302 |  Validation loss: 1.8116690516471863 | Validation Accuracy: 0.9738452434539795\n",
      "\t distressing for many reasons but quite unavoidable -\n",
      "_                _\n",
      "Epoch 7: Train loss: 1.8227104097604752 | Train Accuracy: 0.8730486631393433 |  Validation loss: 1.8445563316345215 | Validation Accuracy: 0.8657170534133911\n",
      "\t for legal charges and stamp duties ,\n",
      "_                    _\n",
      "Epoch 8: Train loss: 1.798730045557022 | Train Accuracy: 0.8475342392921448 |  Validation loss: 1.8959567844867706 | Validation Accuracy: 0.8448941707611084\n",
      "\t peace of mind ? Philip put out\n",
      "_                      _\n",
      "Epoch 9: Train loss: 1.7711028084158897 | Train Accuracy: 0.8518206477165222 |  Validation loss: 1.7760441303253174 | Validation Accuracy: 0.8376866579055786\n",
      "\t talks with the Soviet Union , for the establishment\n",
      "_                                _\n",
      "Epoch 10: Train loss: 1.7489852756261826 | Train Accuracy: 0.8453127145767212 |  Validation loss: 1.6858855485916138 | Validation Accuracy: 0.8347458243370056\n",
      "\t homoeopathy had been brought to his notice .\n",
      "_                                      _\n",
      "Epoch 11: Train loss: 1.7426980063319206 | Train Accuracy: 0.8541662096977234 |  Validation loss: 1.801761120557785 | Validation Accuracy: 0.8469131588935852\n",
      "\t Thus learning how to learn means becoming\n",
      "_                        _\n",
      "Epoch 12: Train loss: 1.7697173655033112 | Train Accuracy: 0.8674007058143616 |  Validation loss: 1.840026319026947 | Validation Accuracy: 0.8705446720123291\n",
      "\t Blanche and Jack left , he went with\n",
      "_                                       _\n",
      "Epoch 13: Train loss: 1.7480585351586342 | Train Accuracy: 0.8436322808265686 |  Validation loss: 1.7337752878665924 | Validation Accuracy: 0.8353043794631958\n",
      "\t moment in disgust . She was fully aware that Gavin\n",
      "_                             _\n",
      "Epoch 14: Train loss: 1.738985389471054 | Train Accuracy: 0.839561939239502 |  Validation loss: 1.8191744685173035 | Validation Accuracy: 0.8345043063163757\n",
      "\t forty and had written Hamlet two years\n",
      "_                                 _\n",
      "Epoch 15: Train loss: 1.7176395878195763 | Train Accuracy: 0.8381245136260986 |  Validation loss: 1.6851631700992584 | Validation Accuracy: 0.8369712829589844\n",
      "\t water that is blown offshore must\n",
      "_                               _\n",
      "Epoch 16: Train loss: 1.7109085097908974 | Train Accuracy: 0.8371534943580627 |  Validation loss: 1.7197619676589966 | Validation Accuracy: 0.8306074738502502\n",
      "\t way left to try to bring home to the people of\n",
      "_                              _\n",
      "Epoch 17: Train loss: 1.7069272994995117 | Train Accuracy: 0.8349927067756653 |  Validation loss: 1.6502390503883362 | Validation Accuracy: 0.8291648030281067\n",
      "\t And , since this is election year in West\n",
      "_                               _\n",
      "Epoch 18: Train loss: 1.7026680558919907 | Train Accuracy: 0.8379480242729187 |  Validation loss: 1.6592750251293182 | Validation Accuracy: 0.8434839248657227\n",
      "\t mid-step near the top of the stairs and\n",
      "_                                     _\n",
      "Epoch 19: Train loss: 1.6959753632545471 | Train Accuracy: 0.834723174571991 |  Validation loss: 1.6509126126766205 | Validation Accuracy: 0.8319382071495056\n",
      "\t ' more like a God upon earth than a human being ' , had an\n",
      "_                                          _\n",
      "Epoch 20: Train loss: 1.6950116083025932 | Train Accuracy: 0.8344754576683044 |  Validation loss: 1.6404520869255066 | Validation Accuracy: 0.8308098316192627\n",
      "\t waiting for the millenium , however , most of us\n",
      "_                                         _\n",
      "Epoch 21: Train loss: 1.6858710870146751 | Train Accuracy: 0.8350984454154968 |  Validation loss: 1.7480249106884003 | Validation Accuracy: 0.8349746465682983\n",
      "\t health permitted him to enjoy\n",
      "_                          _\n",
      "Epoch 22: Train loss: 1.6818523705005646 | Train Accuracy: 0.8299752473831177 |  Validation loss: 1.694957286119461 | Validation Accuracy: 0.8176546096801758\n",
      "\t a roll or a codex . Rolls were prepared for\n",
      "_                                       _\n",
      "Epoch 23: Train loss: 1.6770326271653175 | Train Accuracy: 0.8327377438545227 |  Validation loss: 1.7050657868385315 | Validation Accuracy: 0.8248298168182373\n",
      "\t This is not a filmed play . It has been con-\n",
      "_                                     _\n",
      "Epoch 24: Train loss: 1.725664459168911 | Train Accuracy: 0.8385944962501526 |  Validation loss: 1.7066590785980225 | Validation Accuracy: 0.8343064188957214\n",
      "\t fine girl , intelligent , and pretty , and I had\n",
      "_                                       _\n",
      "Epoch 25: Train loss: 1.6821311712265015 | Train Accuracy: 0.8328883647918701 |  Validation loss: 1.71627876162529 | Validation Accuracy: 0.8278404474258423\n",
      "\t but I really tremble for my country ! I may\n",
      "_                                    _\n",
      "Epoch 26: Train loss: 1.6680479049682617 | Train Accuracy: 0.830788254737854 |  Validation loss: 1.757169395685196 | Validation Accuracy: 0.832658052444458\n",
      "\t carried on .\n",
      "__\n",
      "Epoch 27: Train loss: 1.6644206568598747 | Train Accuracy: 0.8222405910491943 |  Validation loss: 1.7206698954105377 | Validation Accuracy: 0.8227031230926514\n",
      "\t and too big when not .\n",
      "_ee                          _\n",
      "Epoch 28: Train loss: 1.6633004918694496 | Train Accuracy: 0.8482268452644348 |  Validation loss: 1.6323764026165009 | Validation Accuracy: 0.8475245833396912\n",
      "\t Mr. Macleod thought the two Rhodesian parties\n",
      "_hh                                 _\n",
      "Epoch 29: Train loss: 1.6481400281190872 | Train Accuracy: 0.8229814171791077 |  Validation loss: 1.6831744313240051 | Validation Accuracy: 0.8187846541404724\n",
      "\t over West Germany's cash offer to help\n",
      "_he                            _\n",
      "Epoch 30: Train loss: 1.6468334272503853 | Train Accuracy: 0.8291015028953552 |  Validation loss: 1.6573123633861542 | Validation Accuracy: 0.8190351128578186\n",
      "\t to catch speculators in shares and property .\n",
      "_hh                                    _\n",
      "Epoch 31: Train loss: 1.6421859711408615 | Train Accuracy: 0.8170012831687927 |  Validation loss: 1.7078536450862885 | Validation Accuracy: 0.8152235150337219\n",
      "\t America an onerous obligation which it\n",
      "_ e                                    _\n",
      "Epoch 32: Train loss: 1.646042138338089 | Train Accuracy: 0.832836925983429 |  Validation loss: 1.6614402532577515 | Validation Accuracy: 0.8309861421585083\n",
      "\t president 89-year-old Earl Russell and\n",
      "_ae                                 _\n",
      "Epoch 33: Train loss: 1.639671914279461 | Train Accuracy: 0.8147352337837219 |  Validation loss: 1.6140758693218231 | Validation Accuracy: 0.8194862604141235\n",
      "\t The journey has been against me , as there has\n",
      "_ae                                           _\n",
      "Epoch 34: Train loss: 1.651012934744358 | Train Accuracy: 0.8448646068572998 |  Validation loss: 1.662457525730133 | Validation Accuracy: 0.8804261088371277\n",
      "\t Macmillan at Chequers .\n",
      "_hh                _\n",
      "Epoch 35: Train loss: 1.6502936407923698 | Train Accuracy: 0.8247296214103699 |  Validation loss: 1.608670324087143 | Validation Accuracy: 0.818253219127655\n",
      "\t Gavin and the girl who had got\n",
      "_oh                      _\n",
      "Epoch 36: Train loss: 1.6397958993911743 | Train Accuracy: 0.8201372623443604 |  Validation loss: 1.578383058309555 | Validation Accuracy: 0.813056230545044\n",
      "\t praying mantis satisfies its voracity by\n",
      "_oh                                     _\n",
      "Epoch 37: Train loss: 1.6290541738271713 | Train Accuracy: 0.8219566941261292 |  Validation loss: 1.6567407548427582 | Validation Accuracy: 0.843639612197876\n",
      "\t It has aroused strong opposition from the anti-Negro\n",
      "_th                                           _\n",
      "Epoch 38: Train loss: 1.6217161044478416 | Train Accuracy: 0.8356315493583679 |  Validation loss: 1.6615022122859955 | Validation Accuracy: 0.8359436392784119\n",
      "\t organs in the human body - and\n",
      "_ah                         _\n",
      "Epoch 39: Train loss: 1.6159604489803314 | Train Accuracy: 0.8213372230529785 |  Validation loss: 1.5540926158428192 | Validation Accuracy: 0.8234823346138\n",
      "\t were lots of children there , and we had\n",
      "_oe                                    _\n",
      "Epoch 40: Train loss: 1.610293559730053 | Train Accuracy: 0.8197017908096313 |  Validation loss: 1.6680753529071808 | Validation Accuracy: 0.8179904222488403\n",
      "\t This is not a filmed play . It has been con-\n",
      "_th                                          _\n",
      "Epoch 41: Train loss: 1.6129376515746117 | Train Accuracy: 0.8370331525802612 |  Validation loss: 1.6590065956115723 | Validation Accuracy: 0.8401939272880554\n",
      "\t thought you were sensible too . Don't\n",
      "_te                                   _\n",
      "Epoch 42: Train loss: 1.6129374578595161 | Train Accuracy: 0.8320901989936829 |  Validation loss: 1.6744613945484161 | Validation Accuracy: 0.8302049040794373\n",
      "\t like limpets to the rock .\n",
      "_th                  _\n",
      "Epoch 43: Train loss: 1.6146763265132904 | Train Accuracy: 0.8176242709159851 |  Validation loss: 1.592163860797882 | Validation Accuracy: 0.8339418172836304\n",
      "\t It is not easy to make an economic\n",
      "_th                                    _\n",
      "Epoch 44: Train loss: 1.612445443868637 | Train Accuracy: 0.8289327621459961 |  Validation loss: 1.7012019157409668 | Validation Accuracy: 0.8234548568725586\n",
      "\t sanction at a rate roughly fifty per cent in\n",
      "_th                                         _\n",
      "Epoch 45: Train loss: 1.6059016585350037 | Train Accuracy: 0.8163222074508667 |  Validation loss: 1.6323771476745605 | Validation Accuracy: 0.8131202459335327\n",
      "\t to 19 .\n",
      "_ _\n",
      "Epoch 46: Train loss: 1.6020344719290733 | Train Accuracy: 0.8258495926856995 |  Validation loss: 1.6509522199630737 | Validation Accuracy: 0.8320202231407166\n",
      "\t he is going out fast ... . What a gay , lively\n",
      "_oh                                       _\n",
      "Epoch 47: Train loss: 1.6033098250627518 | Train Accuracy: 0.8193769454956055 |  Validation loss: 1.6472946107387543 | Validation Accuracy: 0.8175618052482605\n",
      "\t solation . We could , perhaps , say whether or not\n",
      "_te                                              _\n",
      "Epoch 48: Train loss: 1.5885238870978355 | Train Accuracy: 0.8214287161827087 |  Validation loss: 1.5867968499660492 | Validation Accuracy: 0.8355085849761963\n",
      "\t beginning to find the stereotyped , flattish , happy\n",
      "_th                                               _\n",
      "Epoch 49: Train loss: 1.5963176414370537 | Train Accuracy: 0.8255742192268372 |  Validation loss: 1.6238057017326355 | Validation Accuracy: 0.8262980580329895\n",
      "\t slowly , \" If you must drag the truth\n",
      "_te                                  _\n",
      "Epoch 50: Train loss: 1.597970888018608 | Train Accuracy: 0.8183448910713196 |  Validation loss: 1.6119781136512756 | Validation Accuracy: 0.8165615797042847\n",
      "\t dare . Show me what you can do and\n",
      "_te                              _\n",
      "Epoch 51: Train loss: 1.5795796290040016 | Train Accuracy: 0.7992895841598511 |  Validation loss: 1.6858414709568024 | Validation Accuracy: 0.8066169023513794\n",
      "\t will distort the observed activity for\n",
      "_ta           e                    _\n",
      "Epoch 52: Train loss: 1.5929831564426422 | Train Accuracy: 0.8188320994377136 |  Validation loss: 1.6560834646224976 | Validation Accuracy: 0.8109323978424072\n",
      "\t There had been many such breakfasts lately since the\n",
      "_th                                              _\n",
      "Epoch 53: Train loss: 1.5896631553769112 | Train Accuracy: 0.8161024451255798 |  Validation loss: 1.6982941925525665 | Validation Accuracy: 0.8335628509521484\n",
      "\t ' more like a God upon earth than a human being ' , had an\n",
      "_th                                                  _\n",
      "Epoch 54: Train loss: 1.5810879692435265 | Train Accuracy: 0.8207698464393616 |  Validation loss: 1.671077013015747 | Validation Accuracy: 0.8374393582344055\n",
      "\t president 89-year-old Earl Russell and\n",
      "_th  ee                          _\n",
      "Epoch 55: Train loss: 1.5825698897242546 | Train Accuracy: 0.8151279091835022 |  Validation loss: 1.683188110589981 | Validation Accuracy: 0.8276914954185486\n",
      "\t The glass tube is 11 cm. long and 1 cm. in internal\n",
      "_the  e                                        _\n",
      "Epoch 56: Train loss: 1.5757802575826645 | Train Accuracy: 0.8078674077987671 |  Validation loss: 1.6288352012634277 | Validation Accuracy: 0.8105019927024841\n",
      "\t huh ? \"\n",
      "_to    _\n",
      "Epoch 57: Train loss: 1.5725294053554535 | Train Accuracy: 0.8119606971740723 |  Validation loss: 1.6390486359596252 | Validation Accuracy: 0.8189665079116821\n",
      "\t So they proceeded to see if the coast\n",
      "_to                               _\n",
      "Epoch 58: Train loss: 1.5664051547646523 | Train Accuracy: 0.8153533339500427 |  Validation loss: 1.659855991601944 | Validation Accuracy: 0.8275733590126038\n",
      "\t alleviation of his painful malady . None of the numerous\n",
      "_theeee                                             _\n",
      "Epoch 59: Train loss: 1.5651817694306374 | Train Accuracy: 0.811994194984436 |  Validation loss: 1.694092035293579 | Validation Accuracy: 0.8122798800468445\n",
      "\t Laud made a positive approach . He set out to increase\n",
      "_tee               e  e  e                   _\n",
      "Epoch 60: Train loss: 1.5689011588692665 | Train Accuracy: 0.8006303310394287 |  Validation loss: 1.6601961255073547 | Validation Accuracy: 0.7958592176437378\n",
      "\t is not asking us to believe that , because of\n",
      "_tar  e                                _\n",
      "Epoch 61: Train loss: 1.5611801370978355 | Train Accuracy: 0.8069329261779785 |  Validation loss: 1.642538070678711 | Validation Accuracy: 0.8148515820503235\n",
      "\t as possible . Anyway the Parsifal affair was far\n",
      "_aa     a         a    a                   _\n",
      "Epoch 62: Train loss: 1.5645322501659393 | Train Accuracy: 0.8158511519432068 |  Validation loss: 1.6302814483642578 | Validation Accuracy: 0.8158934116363525\n",
      "\t sure the Labour movement was coming round in\n",
      "_tee   eeeeeeee eeeeeeee  e    e   e  ee  eee _\n",
      "Epoch 63: Train loss: 1.5633808299899101 | Train Accuracy: 0.8035580515861511 |  Validation loss: 1.7087298035621643 | Validation Accuracy: 0.8021575808525085\n",
      "\t been subjected ever since the symptoms\n",
      "_tee    eeee e      ee                 _\n",
      "Epoch 64: Train loss: 1.5552561208605766 | Train Accuracy: 0.7961187362670898 |  Validation loss: 1.6582856178283691 | Validation Accuracy: 0.7925043106079102\n",
      "\t electrodes are completely separated from one\n",
      "_weeeeeee        eeeeeee e     e  e  _\n",
      "Epoch 65: Train loss: 1.5517621487379074 | Train Accuracy: 0.7904087901115417 |  Validation loss: 1.6723166704177856 | Validation Accuracy: 0.7936241030693054\n",
      "\t it .\n",
      "_t ....._\n",
      "Epoch 66: Train loss: 1.5525381937623024 | Train Accuracy: 0.8019352555274963 |  Validation loss: 1.65097314119339 | Validation Accuracy: 0.8014715909957886\n",
      "\t steadily and looked about the room ,\n",
      "_teeeeee          e    e         _\n",
      "Epoch 67: Train loss: 1.5793462917208672 | Train Accuracy: 0.7902229428291321 |  Validation loss: 1.6243212223052979 | Validation Accuracy: 0.7893921136856079\n",
      "\t developed by a firm specialising in electronics\n",
      "_tasaee              e a                   _\n",
      "Epoch 68: Train loss: 1.5622485876083374 | Train Accuracy: 0.7893597483634949 |  Validation loss: 1.6326165199279785 | Validation Accuracy: 0.8195396661758423\n",
      "\t at the return of Ultratoryism , that the Commons\n",
      "_th       ae      ae eaaa a ae a   eeeeeeae_\n",
      "Epoch 69: Train loss: 1.547916255891323 | Train Accuracy: 0.7931966781616211 |  Validation loss: 1.6990974247455597 | Validation Accuracy: 0.7872599363327026\n",
      "\t We must learn all we can about\n",
      "_th    ae e e                  _\n",
      "Epoch 70: Train loss: 1.5425484627485275 | Train Accuracy: 0.8016566038131714 |  Validation loss: 1.6252782344818115 | Validation Accuracy: 0.7928062081336975\n",
      "\t to catch speculators in shares and property .\n",
      "_th  ae     a ee e         etee t          _\n",
      "Epoch 71: Train loss: 1.544353373348713 | Train Accuracy: 0.7943896651268005 |  Validation loss: 1.6992642879486084 | Validation Accuracy: 0.8069815039634705\n",
      "\t sulphate . Lead and strontium form mixed cry-\n",
      "_whsree        a e   e a ea aa    e  e        _\n",
      "Epoch 72: Train loss: 1.539961889386177 | Train Accuracy: 0.8054143190383911 |  Validation loss: 1.7103513479232788 | Validation Accuracy: 0.8132674098014832\n",
      "\t more and came up with two\n",
      "_whme                      _\n",
      "Epoch 73: Train loss: 1.542796477675438 | Train Accuracy: 0.7987787127494812 |  Validation loss: 1.6311761736869812 | Validation Accuracy: 0.8107035756111145\n",
      "\t as days of HEAVEN ON EARTH \" That\n",
      "_te  aee         ee              _\n",
      "Epoch 74: Train loss: 1.5311114639043808 | Train Accuracy: 0.7934106588363647 |  Validation loss: 1.6559285819530487 | Validation Accuracy: 0.7967869639396667\n",
      "\t praying mantis satisfies its voracity by\n",
      "_taeeee     eieeee  ee e ee    e e_\n",
      "Epoch 75: Train loss: 1.537355676293373 | Train Accuracy: 0.7828230261802673 |  Validation loss: 1.6431709229946136 | Validation Accuracy: 0.7848242521286011\n",
      "\t assumption of the government by the Duke of Wellington .\n",
      "_thmeeeeeee          e               e  e       ee  e_\n",
      "Epoch 76: Train loss: 1.5281598642468452 | Train Accuracy: 0.7911851406097412 |  Validation loss: 1.6711986362934113 | Validation Accuracy: 0.7911981344223022\n",
      "\t sulphate . Lead and strontium form mixed cry-\n",
      "_tarree        a e   e aeeeea ee  e eeeaeaeaae_\n",
      "Epoch 77: Train loss: 1.5242774710059166 | Train Accuracy: 0.7908437252044678 |  Validation loss: 1.603381484746933 | Validation Accuracy: 0.7901803851127625\n",
      "\t sombrely : ' Have you ever heard of a punishment called\n",
      "_thrre        t                              _\n",
      "Epoch 78: Train loss: 1.5242374241352081 | Train Accuracy: 0.7926581501960754 |  Validation loss: 1.651873618364334 | Validation Accuracy: 0.8136764764785767\n",
      "\t no major complication but results from an\n",
      "_trrrse       s s                      _\n",
      "Epoch 79: Train loss: 1.5168703719973564 | Train Accuracy: 0.7851600646972656 |  Validation loss: 1.658199816942215 | Validation Accuracy: 0.78461754322052\n",
      "\t fore ! ' After the curry , I wanted only to go upstairs to\n",
      "_the                                                   _\n",
      "Epoch 80: Train loss: 1.5143495947122574 | Train Accuracy: 0.7815923094749451 |  Validation loss: 1.6359659433364868 | Validation Accuracy: 0.7873831391334534\n",
      "\t sequentially operated : the closing of the shutter\n",
      "_Theeie                                         _\n",
      "Epoch 81: Train loss: 1.5080471709370613 | Train Accuracy: 0.7908042669296265 |  Validation loss: 1.636340707540512 | Validation Accuracy: 0.8033560514450073\n",
      "\t revered master at Ko\"then , near\n",
      "_teeeee       e  e               _\n",
      "Epoch 82: Train loss: 1.508800745010376 | Train Accuracy: 0.7940932512283325 |  Validation loss: 1.6450596749782562 | Validation Accuracy: 0.8037863373756409\n",
      "\t mistresses . Anyway it might be much worse .\n",
      "_tueiiii      iieie   eea         ee    _\n",
      "Epoch 83: Train loss: 1.517930120229721 | Train Accuracy: 0.7749125957489014 |  Validation loss: 1.665373533964157 | Validation Accuracy: 0.7721056938171387\n",
      "\t whom Anglesey consulted in May 1834 .\n",
      "_Theee   a        eea                _\n",
      "Epoch 84: Train loss: 1.5267186984419823 | Train Accuracy: 0.7843365669250488 |  Validation loss: 1.6964151859283447 | Validation Accuracy: 0.8080030679702759\n",
      "\t retrieving lost property .\n",
      "_tororer          o    t _\n",
      "Epoch 85: Train loss: 1.5131587460637093 | Train Accuracy: 0.7906796336174011 |  Validation loss: 1.700797587633133 | Validation Accuracy: 0.8013908863067627\n",
      "\t than forty or fifty days after preparation , the\n",
      "_thot te      e   ee e  a      ii e      eee  e _\n",
      "Epoch 86: Train loss: 1.5094790905714035 | Train Accuracy: 0.776889443397522 |  Validation loss: 1.6445520520210266 | Validation Accuracy: 0.7859609127044678\n",
      "\t start and a good finish are half the battle .\n",
      "_tes   at       e  e      e        e  et _\n",
      "Epoch 87: Train loss: 1.5008585378527641 | Train Accuracy: 0.7724190950393677 |  Validation loss: 1.6717506647109985 | Validation Accuracy: 0.7838337421417236\n",
      "\t geography . Geography , too , names the\n",
      "_mommini             e            e    _\n",
      "Epoch 88: Train loss: 1.4958568662405014 | Train Accuracy: 0.7701141834259033 |  Validation loss: 1.7063001990318298 | Validation Accuracy: 0.7812204957008362\n",
      "\t I wish I went to that school . Did you notice\n",
      "_Ihee          e   e      e                     _\n",
      "Epoch 89: Train loss: 1.4946123659610748 | Train Accuracy: 0.7791662216186523 |  Validation loss: 1.6820776462554932 | Validation Accuracy: 0.7882702350616455\n",
      "\t Herring fishermen call this \" the outset \" . It\n",
      "_Trreee                                         _\n",
      "Epoch 90: Train loss: 1.493502914905548 | Train Accuracy: 0.7706791758537292 |  Validation loss: 1.679634302854538 | Validation Accuracy: 0.7617365121841431\n",
      "\t put Vittoria on guard . ' Santa Maria ! These spying\n",
      "_ao   u     e   e                    s          _\n",
      "Epoch 91: Train loss: 1.4990713447332382 | Train Accuracy: 0.775056004524231 |  Validation loss: 1.6016406416893005 | Validation Accuracy: 0.7939363718032837\n",
      "\t solation . We could , perhaps , say whether or not\n",
      "_tolrrr        e e   e e e aa ee ae  eeee        _\n",
      "Epoch 92: Train loss: 1.4934783577919006 | Train Accuracy: 0.7650908827781677 |  Validation loss: 1.6348922550678253 | Validation Accuracy: 0.7731379270553589\n",
      "\t passes on through two pairs of\n",
      "_paette     aaaee         o    _\n",
      "Epoch 93: Train loss: 1.4991644695401192 | Train Accuracy: 0.7723114490509033 |  Validation loss: 1.7221699357032776 | Validation Accuracy: 0.7971486449241638\n",
      "\t romantic than large houses . We drank\n",
      "_aalaae s   e          a              _\n",
      "Epoch 94: Train loss: 1.4870712459087372 | Train Accuracy: 0.7706879377365112 |  Validation loss: 1.6704210340976715 | Validation Accuracy: 0.783734917640686\n",
      "\t peace of mind ? Philip put out\n",
      "_aaaca  aaaatne     n     i     _\n",
      "Epoch 95: Train loss: 1.4839766025543213 | Train Accuracy: 0.7678459882736206 |  Validation loss: 1.649767518043518 | Validation Accuracy: 0.7969352602958679\n",
      "\t \" Better ask Robbie Munyard . \" \" What 's he been\n",
      "_telet  e  t     eeeee    e           tt   t ttt _\n",
      "Epoch 96: Train loss: 1.4769883677363396 | Train Accuracy: 0.770997166633606 |  Validation loss: 1.6647155582904816 | Validation Accuracy: 0.817807674407959\n",
      "\t round a doll's house .\n",
      "_tnme        rm n      _\n",
      "Epoch 97: Train loss: 1.4714431688189507 | Train Accuracy: 0.7641144394874573 |  Validation loss: 1.7169277966022491 | Validation Accuracy: 0.8152626752853394\n",
      "\t dy . None of the numerous conventional\n",
      "_Te    n          eee nnr no   e  _\n",
      "Epoch 98: Train loss: 1.4729105830192566 | Train Accuracy: 0.7646036744117737 |  Validation loss: 1.6838856935501099 | Validation Accuracy: 0.783271074295044\n",
      "\t and sensation-hunger of that\n",
      "_tue   ttttttoe e         o  _\n",
      "Epoch 99: Train loss: 1.4770611971616745 | Train Accuracy: 0.778946578502655 |  Validation loss: 1.6865885555744171 | Validation Accuracy: 0.821548581123352\n",
      "\t rate , have proved that wrong . And they say , too ,\n",
      "_thue    oao ae        e e       ee              e _\n",
      "Epoch 100: Train loss: 1.4794377610087395 | Train Accuracy: 0.7649067640304565 |  Validation loss: 1.7337617576122284 | Validation Accuracy: 0.7791719436645508\n",
      "\t technical error in allowing Irene to speak for\n",
      "_tnrcirit        i  ee e       e  eeeeee   _\n",
      "Epoch 101: Train loss: 1.463970623910427 | Train Accuracy: 0.7516461610794067 |  Validation loss: 1.7120555341243744 | Validation Accuracy: 0.7660201787948608\n",
      "\t now put forward nominees . He believes\n",
      "_wee eee     eeeeae  eeeae e       e  _\n",
      "Epoch 102: Train loss: 1.4578896090388298 | Train Accuracy: 0.759576678276062 |  Validation loss: 1.6108589172363281 | Validation Accuracy: 0.7779614329338074\n",
      "\t finmarchicus in the summer at\n",
      "_phesiinnni e        enntee  _\n",
      "Epoch 103: Train loss: 1.4508735537528992 | Train Accuracy: 0.7573359608650208 |  Validation loss: 1.6847893595695496 | Validation Accuracy: 0.7734241485595703\n",
      "\t ' Good heavens , darling , why on earth\n",
      "_dhee    ei           a  t    t        _\n",
      "Epoch 104: Train loss: 1.4527986273169518 | Train Accuracy: 0.7653664946556091 |  Validation loss: 1.733212172985077 | Validation Accuracy: 0.7922716736793518\n",
      "\t It 's hereabouts that the budge takes to the bottle , but I\n",
      "_'e' h  tttttt  t    e        tttt e  t   tttett _\n",
      "Epoch 105: Train loss: 1.4478817209601402 | Train Accuracy: 0.7545678615570068 |  Validation loss: 1.7044253647327423 | Validation Accuracy: 0.7860273718833923\n",
      "\t a half years ago . Nevertheless there is little\n",
      "_t  ae   eene  e          m   e     ee  e eeeeeeee_\n",
      "Epoch 106: Train loss: 1.4412285387516022 | Train Accuracy: 0.7597038745880127 |  Validation loss: 1.6470999121665955 | Validation Accuracy: 0.7984063625335693\n",
      "\t master at Ko\"then , near Leipzig , asking for\n",
      "_thtthe         eee  eee eeeee e     e e     _\n",
      "Epoch 107: Train loss: 1.4481098353862762 | Train Accuracy: 0.7473688125610352 |  Validation loss: 1.7573058009147644 | Validation Accuracy: 0.7617734670639038\n",
      "\t her over . She has a foot of\n",
      "_whe ene    aae e         a _\n",
      "Epoch 108: Train loss: 1.4424125328660011 | Train Accuracy: 0.7485868334770203 |  Validation loss: 1.701953798532486 | Validation Accuracy: 0.7831183671951294\n",
      "\t gave a concert at which the accompanist was the village schoolmaster ,\n",
      "_suie   eioi es    e       e     ea                   n   aaa_\n",
      "Epoch 109: Train loss: 1.4435323402285576 | Train Accuracy: 0.7639126181602478 |  Validation loss: 1.7537997663021088 | Validation Accuracy: 0.8153377175331116\n",
      "\t Extra-Mural Education Committee and departments\n",
      "_Mhee  sua    eeee e ea e     ee reeeer rr     _\n",
      "Epoch 110: Train loss: 1.4370877668261528 | Train Accuracy: 0.7499493360519409 |  Validation loss: 1.7226505279541016 | Validation Accuracy: 0.8066108822822571\n",
      "\t weight by a flat-rate tax at treble the rate - every adult\n",
      "_Ieee                e  a                  t    eae  _\n",
      "Epoch 111: Train loss: 1.4621835872530937 | Train Accuracy: 0.7571283578872681 |  Validation loss: 1.8298697173595428 | Validation Accuracy: 0.7773240208625793\n",
      "\t seventeen years before had had the slightest effect .\n",
      "_wevieea    ss   e e e          a    ee  a    e eeeses_\n",
      "Epoch 112: Train loss: 1.4544028416275978 | Train Accuracy: 0.752344012260437 |  Validation loss: 1.7802611291408539 | Validation Accuracy: 0.7889103293418884\n",
      "\t with inch and a quarter galvanized nails , if\n",
      "_wat       a         rn nn            e     _\n",
      "Epoch 113: Train loss: 1.431534081697464 | Train Accuracy: 0.7526233792304993 |  Validation loss: 1.7386633455753326 | Validation Accuracy: 0.7826012969017029\n",
      "\t Certainly teenagers earn more than ever before .\n",
      "_cermiiss  eeeeaer    aea ae     aeeeeeeeeee    e_\n",
      "Epoch 114: Train loss: 1.417467638850212 | Train Accuracy: 0.7510563135147095 |  Validation loss: 1.7164521217346191 | Validation Accuracy: 0.863076388835907\n",
      "\t mance of rare intelligence and restrained\n",
      "_tamii          een ae            eeeee  _\n",
      "Epoch 115: Train loss: 1.4178479462862015 | Train Accuracy: 0.7487912178039551 |  Validation loss: 1.6271892189979553 | Validation Accuracy: 0.826897919178009\n",
      "\t It seemed probable that the motive had been\n",
      "_Io Ineeee o n n o  r a ha t    ah   e   t _\n",
      "Epoch 116: Train loss: 1.4090192764997482 | Train Accuracy: 0.7496100068092346 |  Validation loss: 1.812373399734497 | Validation Accuracy: 0.8130340576171875\n",
      "\t I 'd marry you myself . \" Gay laughed , Doc was\n",
      "_I   hmtie        ae    a      eaa              _\n",
      "Epoch 117: Train loss: 1.4127419888973236 | Train Accuracy: 0.7462959885597229 |  Validation loss: 1.8156436085700989 | Validation Accuracy: 0.813035249710083\n",
      "\t Govr. and Compa. of the Bank of England would never\n",
      "_thvr  a   o o  e     a   a    a               _\n",
      "Epoch 118: Train loss: 1.4162382036447525 | Train Accuracy: 0.7430089116096497 |  Validation loss: 1.9855732321739197 | Validation Accuracy: 0.7840901017189026\n",
      "\t developed for an hour before lunch .\n",
      "_ahvnnne     h e   e    r   e  ee_\n",
      "Epoch 119: Train loss: 1.398889221251011 | Train Accuracy: 0.7427482008934021 |  Validation loss: 1.6966231763362885 | Validation Accuracy: 0.7855945825576782\n",
      "\t Monday to Friday were days one\n",
      "_Mosdtttt  i a  e e  ett        _\n",
      "Epoch 120: Train loss: 1.4008031114935875 | Train Accuracy: 0.7370241284370422 |  Validation loss: 1.8621225655078888 | Validation Accuracy: 0.7840989828109741\n",
      "\t search for an effective alleviation of his painful\n",
      "_taass a o   eee  ee   eteo eeee  e ee     e ee_\n",
      "Epoch 121: Train loss: 1.3867304921150208 | Train Accuracy: 0.7366994023323059 |  Validation loss: 1.6280286014080048 | Validation Accuracy: 0.7942909598350525\n",
      "\t fish and the gentle putter of the engine\n",
      "_thse hhh  e  eee  e ee a e      a e  ee_\n",
      "Epoch 122: Train loss: 1.393272802233696 | Train Accuracy: 0.7289654016494751 |  Validation loss: 1.7843426167964935 | Validation Accuracy: 0.776832103729248\n",
      "\t be on the point of death , the new German curative\n",
      "_te mot  e  pp e  h  t       e   e a    a   aea ap_\n",
      "Epoch 123: Train loss: 1.3825352117419243 | Train Accuracy: 0.7374477386474609 |  Validation loss: 1.7916788756847382 | Validation Accuracy: 0.7759567499160767\n",
      "\t had formerly been reluctant to approve the\n",
      "_hhe ttreanan n  e eeeee i ien   oo   e   _\n",
      "Epoch 124: Train loss: 1.3748065531253815 | Train Accuracy: 0.7358859777450562 |  Validation loss: 1.6933155059814453 | Validation Accuracy: 0.7898291349411011\n",
      "\t talents and responsibilities could bring in the open\n",
      "_raaeeaa  rrritei iiiiiiiii i e            e  iii_\n",
      "Epoch 125: Train loss: 1.374491661787033 | Train Accuracy: 0.7278203964233398 |  Validation loss: 1.7294760346412659 | Validation Accuracy: 0.7775517702102661\n",
      "\t delicacy - sought inspiration at last from\n",
      "_lhsrlyy      eiiiii iimp  it    iii      _\n",
      "Epoch 126: Train loss: 1.3609554022550583 | Train Accuracy: 0.7259323000907898 |  Validation loss: 1.7439032196998596 | Validation Accuracy: 0.7797817587852478\n",
      "\t This director is at last being re-evaluated and\n",
      "_Thot h r oo    a a  aa          t e ee ataa t_\n",
      "Epoch 127: Train loss: 1.3639966249465942 | Train Accuracy: 0.7315550446510315 |  Validation loss: 1.7953464984893799 | Validation Accuracy: 0.805321216583252\n",
      "\t he was merely interested in the unfamiliar\n",
      "_te aae esorae    rnnese nerieee aeiinernne_\n",
      "Epoch 128: Train loss: 1.3557042330503464 | Train Accuracy: 0.7227291464805603 |  Validation loss: 1.7379166781902313 | Validation Accuracy: 0.7814704775810242\n",
      "\t which have been carried out .\n",
      "_weec     at  t   e  e    i_\n",
      "Epoch 129: Train loss: 1.3756801560521126 | Train Accuracy: 0.7234731912612915 |  Validation loss: 1.8011744916439056 | Validation Accuracy: 0.7923264503479004\n",
      "\t is not asking us to believe that , because of\n",
      "_te niitiini   o   i  a a  a e  i i  ee i   nn_\n",
      "Epoch 130: Train loss: 1.3759290724992752 | Train Accuracy: 0.7295117974281311 |  Validation loss: 1.8088914155960083 | Validation Accuracy: 0.7946107387542725\n",
      "\t to 19 .\n",
      "_tt _\n",
      "Epoch 131: Train loss: 1.356109768152237 | Train Accuracy: 0.7298384308815002 |  Validation loss: 1.952622503042221 | Validation Accuracy: 0.7860060930252075\n",
      "\t technical error in allowing Irene to speak for\n",
      "_cucciitt    h   re  a e e        t  eee t   ee_\n",
      "Epoch 132: Train loss: 1.3473471328616142 | Train Accuracy: 0.7208878397941589 |  Validation loss: 1.7696821987628937 | Validation Accuracy: 0.8052173852920532\n",
      "\t sure the Labour movement was coming round in\n",
      "_rure  he  a e   eeoouee  o    a a a aaa   i _\n",
      "Epoch 133: Train loss: 1.341665729880333 | Train Accuracy: 0.7228915691375732 |  Validation loss: 1.7714617252349854 | Validation Accuracy: 0.7995762228965759\n",
      "\t disc solo pianist were greatly enhanced when he dug out\n",
      "_ssr  amne ntenn taaeeee eeeene e  ee e eeee   e  en nnn_\n",
      "Epoch 134: Train loss: 1.3285854309797287 | Train Accuracy: 0.7259110808372498 |  Validation loss: 1.7960516214370728 | Validation Accuracy: 0.8450772762298584\n",
      "\t about the nuptial arrangements .\n",
      "_hhoe   h  rrr aaourrruo rm.ues_\n",
      "Epoch 135: Train loss: 1.3349696099758148 | Train Accuracy: 0.7111822962760925 |  Validation loss: 1.7651959657669067 | Validation Accuracy: 0.800726592540741\n",
      "\t ' Good heavens , darling , why on earth\n",
      "_GGGo    ee        e  e               _\n",
      "Epoch 136: Train loss: 1.3256499618291855 | Train Accuracy: 0.7120968103408813 |  Validation loss: 1.8998958766460419 | Validation Accuracy: 0.7727989554405212\n",
      "\t feather-weight contest between Chris Elliot and\n",
      "_tes \"nttwwa haheie  e eatane    ii   tt ttt tt_\n",
      "Epoch 137: Train loss: 1.3264691457152367 | Train Accuracy: 0.7167986035346985 |  Validation loss: 1.8046340346336365 | Validation Accuracy: 0.8045135140419006\n",
      "\t the tapestries , and in the general\n",
      "_the  fameaana     e e r ae e     _\n",
      "Epoch 138: Train loss: 1.3263559937477112 | Train Accuracy: 0.7144126296043396 |  Validation loss: 1.7699674665927887 | Validation Accuracy: 0.8029428124427795\n",
      "\t passed all too quickly . As they parted in\n",
      "_werrea bll  w  eee  e         e  ee  e    _\n",
      "Epoch 139: Train loss: 1.3031415492296219 | Train Accuracy: 0.7019839286804199 |  Validation loss: 1.8829266726970673 | Validation Accuracy: 0.7884907722473145\n",
      "\t history of Anglesey's unceasing search for an\n",
      "_hast r    hoeduee e eetr reea eeeaan  _\n",
      "Epoch 140: Train loss: 1.3033079653978348 | Train Accuracy: 0.6978663206100464 |  Validation loss: 1.8133589625358582 | Validation Accuracy: 0.7718234062194824\n",
      "\t dy . None of the numerous conventional\n",
      "_Th  hoo o   at   meaen ma ano tc  n_\n",
      "Epoch 141: Train loss: 1.3028229251503944 | Train Accuracy: 0.7027133703231812 |  Validation loss: 1.7755178213119507 | Validation Accuracy: 0.8003123998641968\n",
      "\t that freedom last if their policies were adopted ?\n",
      "_thlt aemmmn  i e  a     i  i    e   e iaaa  dee  e_\n",
      "Epoch 142: Train loss: 1.2910957336425781 | Train Accuracy: 0.6999409794807434 |  Validation loss: 1.8602071702480316 | Validation Accuracy: 0.8117716312408447\n",
      "\t relieve his feelings . On the small-to-medium\n",
      "_rerreve  hsifeee  e       e e  teehe       ee_\n",
      "Epoch 143: Train loss: 1.2879207283258438 | Train Accuracy: 0.7029079794883728 |  Validation loss: 1.8950569033622742 | Validation Accuracy: 0.8213576078414917\n",
      "\t solation . We could , perhaps , say whether or not\n",
      "_loltti t    r  cu   d at    a e ai  a t         n_\n",
      "Epoch 144: Train loss: 1.2826011404395103 | Train Accuracy: 0.6921840906143188 |  Validation loss: 1.8216280341148376 | Validation Accuracy: 0.7902105450630188\n",
      "\t this had already happened half a dozen times .\n",
      "_hhis ha  anaen    e  e  e a        es   nsaa  a_\n",
      "Epoch 145: Train loss: 1.2760943099856377 | Train Accuracy: 0.6919525861740112 |  Validation loss: 1.8316538631916046 | Validation Accuracy: 0.7820018529891968\n",
      "\t wrote , ' is arrived , which is a great resource . Vesuvius\n",
      "_brtly  .' es eer ee             s ee ssese           ii iss_\n",
      "Epoch 146: Train loss: 1.268831118941307 | Train Accuracy: 0.6895257830619812 |  Validation loss: 1.8546189665794373 | Validation Accuracy: 0.7851706743240356\n",
      "\t large majority of Labour M Ps are likely to\n",
      "_warre emjooooo aree eee  o oo    eeo o  ooo_\n",
      "Epoch 147: Train loss: 1.2581734955310822 | Train Accuracy: 0.6819379925727844 |  Validation loss: 1.8893397748470306 | Validation Accuracy: 0.7872827649116516\n",
      "\t then Philip was so certain that Nicholas\n",
      "_the'   iii  ee       e ae    irnia  en_\n",
      "Epoch 148: Train loss: 1.251748487353325 | Train Accuracy: 0.6870397925376892 |  Validation loss: 1.9156575500965118 | Validation Accuracy: 0.8065842390060425\n",
      "\t above the boney knob which landmarked the cervical\n",
      "_Wbbve i    oa   o o  i a t a  aa t        eee eae_\n",
      "Epoch 149: Train loss: 1.2440817952156067 | Train Accuracy: 0.6820862889289856 |  Validation loss: 2.0177850127220154 | Validation Accuracy: 0.7889817953109741\n",
      "\t with a book on the life of Marx ,\n",
      "_wath a bobo o      oi    r   of_\n",
      "Epoch 150: Train loss: 1.2322384119033813 | Train Accuracy: 0.6782054305076599 |  Validation loss: 1.9855406284332275 | Validation Accuracy: 0.7997218370437622\n",
      "\t and that there was no hope of final victory\n",
      "_tnd thee  t i   r      te   e  et e  eee_\n",
      "Epoch 151: Train loss: 1.2463564723730087 | Train Accuracy: 0.6808332204818726 |  Validation loss: 1.946292519569397 | Validation Accuracy: 0.7839433550834656\n",
      "\t fore ! ' After the curry , I wanted only to go upstairs to\n",
      "_Aor  oa   t    ea a   e  oao o o  o      o   t  ttt  _\n",
      "Epoch 152: Train loss: 1.233937807381153 | Train Accuracy: 0.672478973865509 |  Validation loss: 1.8395207226276398 | Validation Accuracy: 0.8004389405250549\n",
      "\t way left to try to bring home to the people of\n",
      "_any iie  tt tta ao oo t ohe      eeeeee  _\n",
      "Epoch 153: Train loss: 1.2232227474451065 | Train Accuracy: 0.6729316115379333 |  Validation loss: 1.8560339510440826 | Validation Accuracy: 0.7912631034851074\n",
      "\t could not have overheard anything they\n",
      "_ooug  ahahh hh  uoueomede     ed  ete_\n",
      "Epoch 154: Train loss: 1.2193760350346565 | Train Accuracy: 0.6778404712677002 |  Validation loss: 1.9515110552310944 | Validation Accuracy: 0.7986980080604553\n",
      "\t impression that nothing nasty ever\n",
      "_iigaiiii    r t ohhh  hte   e h  e_\n",
      "Epoch 155: Train loss: 1.2275983691215515 | Train Accuracy: 0.672542154788971 |  Validation loss: 1.8853483200073242 | Validation Accuracy: 0.7886561155319214\n",
      "\t the new German curative method known as\n",
      "_the tye  epes hll vae   netvte  e ee e_\n",
      "Epoch 156: Train loss: 1.2031286358833313 | Train Accuracy: 0.671215832233429 |  Validation loss: 2.0007789731025696 | Validation Accuracy: 0.8376374244689941\n",
      "\t the water has been suggested on\n",
      "_teewrnttttser eerh g  ogoo  s  _\n",
      "Epoch 157: Train loss: 1.1960646957159042 | Train Accuracy: 0.6602378487586975 |  Validation loss: 1.9798499941825867 | Validation Accuracy: 0.8228800296783447\n",
      "\t history of Anglesey's unceasing search for an\n",
      "_hntttr     f dueeee rssr ieiacscernatr  rr aa_\n",
      "Epoch 158: Train loss: 1.1881234496831894 | Train Accuracy: 0.6521943807601929 |  Validation loss: 1.8986814618110657 | Validation Accuracy: 0.7966552972793579\n",
      "\t keeping B flat on the chair seat , and mark\n",
      "_knevigs   B ae   ht e t  aetee  eeeee ee e_\n",
      "Epoch 159: Train loss: 1.1763476133346558 | Train Accuracy: 0.6518990993499756 |  Validation loss: 1.9176098704338074 | Validation Accuracy: 0.8015972375869751\n",
      "\t home , or perhaps a student studying to\n",
      "_saseh  o  mopmito e a  e  a e h  n   as_\n",
      "Epoch 160: Train loss: 1.1891490668058395 | Train Accuracy: 0.6644186973571777 |  Validation loss: 1.9664457142353058 | Validation Accuracy: 0.814314603805542\n",
      "\t dare . Show me what you can do and\n",
      "_ddrn . S oa a  eaae   a  a n a  a _\n",
      "Epoch 161: Train loss: 1.1860461235046387 | Train Accuracy: 0.6484306454658508 |  Validation loss: 1.968420833349228 | Validation Accuracy: 0.8126929998397827\n",
      "\t but I really tremble for my country ! I may\n",
      "_tnt I chleee eee  le   a aeeea i o  e   say_\n",
      "Epoch 162: Train loss: 1.1709125638008118 | Train Accuracy: 0.6482367515563965 |  Validation loss: 1.992588996887207 | Validation Accuracy: 0.8050713539123535\n",
      "\t Station , and a stretcher party took the body to\n",
      "_tlrtno n  an  atotyng      aa   hetahe  hhha   _\n",
      "Epoch 163: Train loss: 1.180378332734108 | Train Accuracy: 0.6451289057731628 |  Validation loss: 1.9840240180492401 | Validation Accuracy: 0.8021100163459778\n",
      "\t He 's quite capable of telling Sir John to take\n",
      "_H H's qooi llsis  ll  a e  k             e set _\n",
      "Epoch 164: Train loss: 1.1575165316462517 | Train Accuracy: 0.6464086771011353 |  Validation loss: 2.017176926136017 | Validation Accuracy: 0.805674135684967\n",
      "\t close agreement of the two Governments in pursuing their\n",
      "_foot   seeeee        t a   mo    o        a e oet  r_\n",
      "Epoch 165: Train loss: 1.1574189439415932 | Train Accuracy: 0.6388404369354248 |  Validation loss: 1.9926724433898926 | Validation Accuracy: 0.8142284750938416\n",
      "\t led the way in . \" The stained glass\n",
      "_wee  hhh wi ii       ee iai .  cst_\n",
      "Epoch 166: Train loss: 1.1374736726284027 | Train Accuracy: 0.6392117142677307 |  Validation loss: 1.9960594773292542 | Validation Accuracy: 0.8187194466590881\n",
      "\t relieve his feelings . On the small-to-medium\n",
      "_relinve   s  eee  t       e e  neem-e   ee te_\n",
      "Epoch 167: Train loss: 1.1379577666521072 | Train Accuracy: 0.6336395740509033 |  Validation loss: 2.2162772715091705 | Validation Accuracy: 0.7934399247169495\n",
      "\t The glass tube is 11 cm. long and 1 cm. in internal\n",
      "_The glssh ilbe is111 mm. m    e   1        ei  eeei_\n",
      "Epoch 168: Train loss: 1.136351764202118 | Train Accuracy: 0.6332998871803284 |  Validation loss: 2.0565582513809204 | Validation Accuracy: 0.8170936107635498\n",
      "\t create the atmosphere of a city .\n",
      "_wowusettthhnrmmmseere efe    e  _\n",
      "Epoch 169: Train loss: 1.1191120892763138 | Train Accuracy: 0.6199367642402649 |  Validation loss: 1.9812537133693695 | Validation Accuracy: 0.8156565427780151\n",
      "\t ment and Satanic debauchery .\n",
      "_weotda    d hee eee e o a e.._\n",
      "Epoch 170: Train loss: 1.1041892915964127 | Train Accuracy: 0.628741443157196 |  Validation loss: 2.113410234451294 | Validation Accuracy: 0.7997595071792603\n",
      "\t This new party , the British Socialist Party , was\n",
      "_Thit law  aa a,,  he  e e eeti ii e s  eeea  ettei_\n",
      "Epoch 171: Train loss: 1.1014374047517776 | Train Accuracy: 0.6279670000076294 |  Validation loss: 2.0530191361904144 | Validation Accuracy: 0.8300111889839172\n",
      "\t Hadley , Prebble , Lambert-Price - the\n",
      "_toaley , Pmbbbl  ,  aseseg  en  . . _\n",
      "Epoch 172: Train loss: 1.1075904220342636 | Train Accuracy: 0.6156858801841736 |  Validation loss: 2.350952923297882 | Validation Accuracy: 0.8041634559631348\n",
      "\t It 's hereabouts that the budge takes to the bottle , but I\n",
      "_It 's  eeeab t s  ha    e  t oot t   t   th  tot ,  ,    _\n",
      "Epoch 173: Train loss: 1.1302898451685905 | Train Accuracy: 0.6184449791908264 |  Validation loss: 2.1169642210006714 | Validation Accuracy: 0.794888973236084\n",
      "\t delicacy - sought inspiration at last from\n",
      "_doeicccy-  suhoau  aaiiaiit  tiiiaat     _\n",
      "Epoch 174: Train loss: 1.099934108555317 | Train Accuracy: 0.6037986874580383 |  Validation loss: 2.0022305846214294 | Validation Accuracy: 0.7983184456825256\n",
      "\t round a doll's house .\n",
      "_ouue     aa''rfer e' a._\n",
      "Epoch 175: Train loss: 1.0978978164494038 | Train Accuracy: 0.6212958693504333 |  Validation loss: 2.1313313245773315 | Validation Accuracy: 0.8254784345626831\n",
      "\t ' Good heavens , darling , why on earth\n",
      "_GnGoo  heeaeas    a eete y a ayedd ee  _\n",
      "Epoch 176: Train loss: 1.0984001457691193 | Train Accuracy: 0.6098715662956238 |  Validation loss: 2.1391386091709137 | Validation Accuracy: 0.7920743823051453\n",
      "\t West Germany . REFUGEES are pouring out\n",
      "_Wist Gmrnnnyy     c a   an   iee  t e_\n",
      "Epoch 177: Train loss: 1.0740039311349392 | Train Accuracy: 0.6062095165252686 |  Validation loss: 2.0782825350761414 | Validation Accuracy: 0.8028851747512817\n",
      "\t was without the right to make such\n",
      "_sas  thtooutte  t e t    tr    a eh _\n",
      "Epoch 178: Train loss: 1.0576859638094902 | Train Accuracy: 0.5995963215827942 |  Validation loss: 2.2111517190933228 | Validation Accuracy: 0.820011556148529\n",
      "\t future . Said Mr. Nkumbula last night :\n",
      "_fltuee . Shhda i. N tmkhta hhan mummn _\n",
      "Epoch 179: Train loss: 1.060712531208992 | Train Accuracy: 0.5923896431922913 |  Validation loss: 2.1177869141101837 | Validation Accuracy: 0.8104556798934937\n",
      "\t are being tried out at present .\n",
      "_iie  enng i r   oot  rrar ae _\n",
      "Epoch 180: Train loss: 1.0537028647959232 | Train Accuracy: 0.6050218939781189 |  Validation loss: 2.059559017419815 | Validation Accuracy: 0.798355758190155\n",
      "\t ever was . But he has not one word of English . '\n",
      "_sher was . Btt h  hts nn  a   taah   ooo os    _\n",
      "Epoch 181: Train loss: 1.0350187420845032 | Train Accuracy: 0.5927941203117371 |  Validation loss: 2.1658204793930054 | Validation Accuracy: 0.8188779354095459\n",
      "\t geography . Geography , too , names the\n",
      "_googrn h h     ee i    ass      sia    _\n",
      "Epoch 182: Train loss: 1.0390797667205334 | Train Accuracy: 0.5891628265380859 |  Validation loss: 2.22585791349411 | Validation Accuracy: 0.8256603479385376\n",
      "\t the party was over . Piers came strolling out to\n",
      "_te  oiptt oas eevrr.e ee er tee sarctgigt inn t_\n",
      "Epoch 183: Train loss: 1.029610302299261 | Train Accuracy: 0.5786117911338806 |  Validation loss: 2.0027080476284027 | Validation Accuracy: 0.8103364109992981\n",
      "\t Herring fishermen call this \" the outset \" . It\n",
      "_Heruint tsseeoat  lt  t       t   ttttt       _\n",
      "Epoch 184: Train loss: 1.0144751705229282 | Train Accuracy: 0.5779135823249817 |  Validation loss: 2.2510433197021484 | Validation Accuracy: 0.7980599403381348\n",
      "\t classes in the early 19th century which\n",
      "_clatse   n .hhheauha t i  h eee  e et_\n",
      "Epoch 185: Train loss: 1.039847955107689 | Train Accuracy: 0.5779771208763123 |  Validation loss: 2.2476483583450317 | Validation Accuracy: 0.7936707139015198\n",
      "\t to meet head-on the biggest challenge to\n",
      "_to mpti h ac-on n    err se nhaca eaa r_\n",
      "Epoch 186: Train loss: 1.02503751963377 | Train Accuracy: 0.5817483067512512 |  Validation loss: 2.2230060696601868 | Validation Accuracy: 0.8321428298950195\n",
      "\t number of households with sole occupation or sharing\n",
      "_muober    hniooil  a  t   asseesreeaeore  rr e eorrr_\n",
      "Epoch 187: Train loss: 1.0282438211143017 | Train Accuracy: 0.5802242159843445 |  Validation loss: 2.225333571434021 | Validation Accuracy: 0.8187324404716492\n",
      "\t passes on through two pairs of\n",
      "_sassel nnoo roeehheee eg r  t_\n",
      "Epoch 188: Train loss: 0.9920788295567036 | Train Accuracy: 0.5643908381462097 |  Validation loss: 2.2004576921463013 | Validation Accuracy: 0.8184385895729065\n",
      "\t who , under apartheid , will be forced back to\n",
      "_who , rdnea raahh,,r  o iiaa to a e u     an_\n",
      "Epoch 189: Train loss: 0.9833514504134655 | Train Accuracy: 0.5641772150993347 |  Validation loss: 2.2182671427726746 | Validation Accuracy: 0.7963911890983582\n",
      "\t hour and a half days if it is\n",
      "_rour haa    aaf  aa  a  t   _\n",
      "Epoch 190: Train loss: 0.9712906144559383 | Train Accuracy: 0.5559020042419434 |  Validation loss: 2.2302294969558716 | Validation Accuracy: 0.8218063712120056\n",
      "\t sedate , not easily irritated , patient and\n",
      "_asdatl , nooouadi   eriititnr , adta taan_\n",
      "Epoch 191: Train loss: 0.9698040708899498 | Train Accuracy: 0.5799290537834167 |  Validation loss: 2.1715961396694183 | Validation Accuracy: 0.8467304110527039\n",
      "\t shaving when it came on , with a flat\n",
      "_s tvins ehen  g  cig at e ege ma   tee_\n",
      "Epoch 192: Train loss: 0.9838449209928513 | Train Accuracy: 0.5602375268936157 |  Validation loss: 2.3228085041046143 | Validation Accuracy: 0.8285808563232422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m recognizer \u001b[39m=\u001b[39m Recognizer()\n\u001b[1;32m      2\u001b[0m \u001b[39m# generator = load_model(generator, \"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)_generator_epoch9.pt\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# generator, encoder, discriminator = load_models_of_same_batch(generator, encoder, discriminator, filename_prefix=\"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)\", epoch_number=9)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train(recognizer\u001b[39m=\u001b[39mrecognizer, \n\u001b[1;32m      6\u001b[0m               train_line_dataset\u001b[39m=\u001b[39mline_dataset_train, val_line_dataset\u001b[39m=\u001b[39mline_dataset_val, \n\u001b[1;32m      7\u001b[0m               batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, recognizer_lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m,\n\u001b[1;32m      8\u001b[0m               betas\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0.999\u001b[39m), num_epochs\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, loss_balancing_alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 74\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(recognizer, train_line_dataset, val_line_dataset, batch_size, recognizer_lr, betas, num_epochs, loss_balancing_alpha)\u001b[0m\n\u001b[1;32m     71\u001b[0m     recognizer_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     72\u001b[0m     recognizer_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 74\u001b[0m     recognizer_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m recognizer_loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     76\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m,test)\n\u001b[1;32m     77\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtest2\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recognizer = Recognizer()\n",
    "# generator = load_model(generator, \"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)_generator_epoch9.pt\")\n",
    "# generator, encoder, discriminator = load_models_of_same_batch(generator, encoder, discriminator, filename_prefix=\"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)\", epoch_number=9)\n",
    "\n",
    "train(recognizer=recognizer, \n",
    "              train_line_dataset=line_dataset_train, val_line_dataset=line_dataset_val, \n",
    "              batch_size=32, recognizer_lr=1e-3,\n",
    "              betas=(0, 0.999), num_epochs=500, loss_balancing_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512])\n",
      "torch.Size([32, 512])\n",
      "tensor([[0.0137, 0.0137, 0.0137,  ..., 0.0137, 0.0139, 0.0137],\n",
      "        [0.0138, 0.0138, 0.0138,  ..., 0.0138, 0.0134, 0.0138],\n",
      "        [0.0137, 0.0138, 0.0137,  ..., 0.0137, 0.0135, 0.0137],\n",
      "        ...,\n",
      "        [0.0140, 0.0140, 0.0140,  ..., 0.0139, 0.0135, 0.0139],\n",
      "        [0.0137, 0.0137, 0.0137,  ..., 0.0138, 0.0139, 0.0137],\n",
      "        [0.0137, 0.0137, 0.0137,  ..., 0.0137, 0.0138, 0.0137]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([82, 73])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = line_dataset_train[0]\n",
    "print(image.shape)\n",
    "plt.title(\"\".join([int_to_char[int(val)] for val in label[label.nonzero()]]))\n",
    "print(image.squeeze(0).shape)\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "label, \"\".join([int_to_char[int(val)] for val in label[label.nonzero()]])\n",
    "\n",
    "print(torch.softmax(recognizer(image.unsqueeze(0)), 1), torch.softmax(recognizer(image.unsqueeze(0)), 1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
