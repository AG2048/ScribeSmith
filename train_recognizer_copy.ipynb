{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizer for Handwritten Text Synthesis GAN\n",
    "\n",
    "This model will consist of 4 major networks, following the general architecture of an GAN.\n",
    "\n",
    "1. Encoder: Produces an embedding that will be concatenated with the noise vector.\n",
    "2. Generator: Taking noise vector as input and the text embedding to produce an 128x2048 image.\n",
    "3. Discriminator: Trained alternating with generator input and ground-truth input, binary classification real or fake.\n",
    "4. Recognizer: Taking image as input, produce a vector representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_fidelity\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torch.nn.utils.spectral_norm import spectral_norm\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, Subset, random_split\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Grayscale, Resize, ToTensor, ToPILImage\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "from torchmetrics.text import CharErrorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (Run once only to format data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Samples: 11073\n",
      "Valid Samples: 7135\n",
      "Total Train Samples: 22828\n",
      "Total Validation Samples: 1428\n"
     ]
    }
   ],
   "source": [
    "SCALE_HEIGHT = 32\n",
    "SCALE_WIDTH = SCALE_HEIGHT*16\n",
    "\n",
    "def preprocess_lines(data_root):\n",
    "    \"\"\"\n",
    "    Creates a new `.txt` file `lines_improved.txt` that will be used\n",
    "    for querying. This new `.txt` file contains all info necessary\n",
    "    for the functionality of this project.\n",
    "    \"\"\"\n",
    "\n",
    "    original_path = os.path.join(data_root, \"lines.txt\")\n",
    "    improved_path = os.path.join(data_root, \"lines_improved_recognizer.txt\")\n",
    "    fi = open(improved_path, \"w\")\n",
    "\n",
    "    # Some variables for tracking\n",
    "    num_samples = 0\n",
    "    valid_samples = 0\n",
    "    total_train_samples = 0\n",
    "    total_val_samples = 0\n",
    "    \n",
    "    # Loop through \"lines.txt\"\n",
    "    with open(original_path, \"r\") as fo:\n",
    "        headers = [\"image_id\", \"image_path\", \"image_pt_path\", \"graylevel\", \"original_height\", \"original_width\", \"transcription\", \"transcription_len\"]\n",
    "\n",
    "        # First write the headers at the top of the file\n",
    "        fi.writelines(\"\\t\".join(headers) + \"\\n\")\n",
    "\n",
    "        # Skip the intro stuff\n",
    "        lines = fo.readlines()\n",
    "        for line_num in range(len(lines)):\n",
    "            \n",
    "            line = lines[line_num]\n",
    "            \n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            # Valid lines, not the intro_text\n",
    "            line_items = line.strip().split(\" \")  # `strip()` to remove newlines\n",
    "\n",
    "            # The actual items (we extract the important ones)\n",
    "            image_id = line_items[0]\n",
    "            status = line_items[1]\n",
    "            graylevel = int(line_items[2])\n",
    "            transcription = \" \".join(line_items[8:])  # Some data has whitespace, we join string till the end\n",
    "\n",
    "            # Skip error images\n",
    "            if status == \"err\":\n",
    "                continue\n",
    "        \n",
    "            # Alphanumeric + common punctuation regex\n",
    "            # Returns None if no match\n",
    "            # 26 + 26 + 10 + 9 + 1 = 72\n",
    "            # Spaces might be included as well\n",
    "            # Punctuation include , ! ? ' \" , : ; -\n",
    "            if re.fullmatch(\"[a-zA-Z0-9.!?'\\\",:;| -]*\", transcription) is None:\n",
    "                continue\n",
    "\n",
    "            # Now we have valid transcription\n",
    "            num_samples += 1\n",
    "\n",
    "            # We get the `.png` image path\n",
    "            inp = image_id.split(\"-\")  # `inp` stands for image name parts\n",
    "            image_path_head = os.path.join(data_root, \"lines\", inp[0], f\"{inp[0]}-{inp[1]}\")\n",
    "            image_path_tail = f\"{image_id}.png\"\n",
    "            image_path = os.path.join(image_path_head, image_path_tail)\n",
    "            \n",
    "            # Read image, gets its dimensions, perform processing operations, and other stuff\n",
    "            tmp_image = cv.imread(os.path.join(image_path_head, image_path_tail), cv.IMREAD_GRAYSCALE)  # Removes the channel dimension\n",
    "            height, width = tmp_image.shape\n",
    "\n",
    "            # Scaling calculations\n",
    "            # If width * scale >= desired length (>= to be safe)\n",
    "            # Condition here to speed up overall processing time\n",
    "            if width * (SCALE_HEIGHT/height) >= SCALE_WIDTH:\n",
    "                continue\n",
    "\n",
    "            resized_tensor = process_image(tmp_image, graylevel, lambda x: x)\n",
    "            image_pt_path = os.path.join(image_path_head, f\"{image_id}.pt\")\n",
    "            torch.save(resized_tensor, image_pt_path)\n",
    "\n",
    "            # A fully valid image\n",
    "            # Separate by underscores because `transcription` has spaces so we can't split by spaces\n",
    "            fi.writelines(f\"{image_id}\\t{image_path}\\t{image_pt_path}\\t{graylevel}\\t{height}\\t{width}\\t{transcription}\\t{len(transcription)}\\n\")\n",
    "            valid_samples += 1\n",
    "\n",
    "            # RECOGNIZER EXCLUSIVE\n",
    "            # Some ways to augment images:\n",
    "            # - horizontally compress\n",
    "            # - horizontally stretch\n",
    "            # - vertically compress\n",
    "            # - vertically stretch\n",
    "            \n",
    "            if valid_samples < 7135*0.8:\n",
    "                        \n",
    "                if len(transcription) >= 30:\n",
    "                    for i in range(3):\n",
    "                        resized_tensor = process_image(tmp_image, graylevel, horizontally_compress)\n",
    "                        image_pt_path = os.path.join(image_path_head, f\"{image_id}hc{i}.pt\")\n",
    "                        torch.save(resized_tensor, image_pt_path)\n",
    "\n",
    "                        # A fully valid image\n",
    "                        # Separate by underscores because `transcription` has spaces so we can't split by spaces\n",
    "                        fi.writelines(f\"{image_id}\\t{image_path}\\t{image_pt_path}\\t{graylevel}\\t{height}\\t{width}\\t{transcription}\\t{len(transcription)}\\n\")\n",
    "                        #valid_samples += 1\n",
    "                        total_train_samples += 1\n",
    "                \n",
    "                elif len(transcription) < 30:\n",
    "                    for i in range(3):\n",
    "                        resized_tensor = process_image(tmp_image, graylevel, horizontally_stretch)\n",
    "                        # Just in case after stretching we have cut off boundary\n",
    "                        if resized_tensor is None:\n",
    "                            continue\n",
    "                        image_pt_path = os.path.join(image_path_head, f\"{image_id}hs{i}.pt\")\n",
    "                        torch.save(resized_tensor, image_pt_path)\n",
    "\n",
    "                        # A fully valid image\n",
    "                        # Separate by underscores because `transcription` has spaces so we can't split by spaces\n",
    "                        fi.writelines(f\"{image_id}\\t{image_path}\\t{image_pt_path}\\t{graylevel}\\t{height}\\t{width}\\t{transcription}\\t{len(transcription)}\\n\")\n",
    "                        #valid_samples += 1\n",
    "                        total_train_samples += 1\n",
    "                total_train_samples += 1\n",
    "            else:\n",
    "                total_val_samples += 1\n",
    "\n",
    "        fi.close()\n",
    "    \n",
    "    print(\"# Samples:\", num_samples)\n",
    "    print(\"Valid Samples:\", valid_samples)\n",
    "    print(\"Total Train Samples:\", total_train_samples)\n",
    "    print(\"Total Validation Samples:\", total_val_samples)\n",
    "\n",
    "\n",
    "def horizontally_compress(cv_image):\n",
    "    \"\"\" by random percent \"\"\"\n",
    "    factor = 1 - random.random()/2\n",
    "    height, width = cv_image.shape\n",
    "    output = cv.resize(cv_image, (width, int(height*factor)), interpolation=cv.INTER_AREA)\n",
    "    return output\n",
    "    ...\n",
    "\n",
    "\n",
    "def horizontally_stretch(cv_image):\n",
    "    \"\"\" by random percent\"\"\"\n",
    "    factor = 1 + random.random()/2\n",
    "    height, width = cv_image.shape\n",
    "    output = cv.resize(cv_image, (width, int(height*factor)), interpolation=cv.INTER_LINEAR)\n",
    "    return output\n",
    "    ...\n",
    "\n",
    "\n",
    "def process_image(cv_image, graylevel, additional_func=None):\n",
    "    \"\"\"\n",
    "    Takes in a grayscale image that OpenCV read of shape (H, W) of type uint8\n",
    "    Returns a PyTorch tensor of shape (1, 32, W'), where W' is the scaled width\n",
    "    This tensor is padded and effectively thresholded\n",
    "    \"\"\"\n",
    "\n",
    "    # Scaling factor\n",
    "    height, width = cv_image.shape\n",
    "    scale = SCALE_HEIGHT/height\n",
    "    scaled_width = int(width*scale)\n",
    "\n",
    "    # Trick here is to apply threshold before resize and padding\n",
    "    # This allows OpenCV resizing to create a cleaner output image\n",
    "    # 2nd return value is the thresholded image\n",
    "    output = cv.threshold(cv_image, graylevel, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "    # Apply additional filter\n",
    "    output = additional_func(output)\n",
    "\n",
    "    # INTER_AREA recommended for sizing down\n",
    "    output = cv.resize(output, (scaled_width, SCALE_HEIGHT), interpolation=cv.INTER_AREA)\n",
    "\n",
    "\n",
    "    # Turn it back to a tensor and map to [0, 1]\n",
    "    output = torch.from_numpy(output).unsqueeze(0).type(torch.float32)\n",
    "    output = (output-output.min()) / (output.max()-output.min())\n",
    "    \n",
    "    # Add padding\n",
    "    _, _, resized_height = output.shape\n",
    "    padding_to_add = SCALE_WIDTH - resized_height\n",
    "\n",
    "    if padding_to_add < 0:\n",
    "        return\n",
    "\n",
    "    output = F.pad(output, (0, padding_to_add), value=1.0)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Uncomment this if your data isn't processed yet\n",
    "preprocess_lines(\"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Dict (Run everytime before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted by ascii code\n",
    "valid = [\n",
    "    ' ', '!', '\"', \"'\", ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "    ':', ';', '?', \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
    "]\n",
    "# Enumerate from 1 to save space for padding\n",
    "# Reserve 0 for CTC blank\n",
    "char_to_int = {v: i for i, v in enumerate(valid, 1)}\n",
    "int_to_char = {i: v for i, v in enumerate(valid, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineDataset(Dataset):\n",
    "    def __init__(self, lines_improved_dir, ty=None):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            lines_improved_dir: path to the `lines_improved.txt` file\n",
    "            ty: type of the dataset \"txt\", \"img\" for text dataset or image dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dataframe containing the stuff in `lines_improved.txt`\n",
    "        self.lines_df = pd.read_csv(lines_improved_dir, sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "        # Class properties\n",
    "        self.ty = ty  # Type of dataset (lines, images, or both)\n",
    "        self.max_transcription_len = max(self.lines_df[\"transcription_len\"])\n",
    "\n",
    "        # Temp variables...\n",
    "        length = self.lines_df.shape[0]\n",
    "        line_datas = self.lines_df.iloc\n",
    "        ret_texts = [line_datas[i][\"transcription\"].replace('|', ' ') for i in range(length)]\n",
    "        ret_ctois = [torch.tensor([char_to_int[char] for char in ret_texts[i]]) for i in range(length)]\n",
    "\n",
    "        # ...for the important data\n",
    "        if self.ty in (\"txt\", None):  # Added this condition to speed thigns up if only text\n",
    "            self.ret_ctoi_paddeds = [F.pad(ret_ctois[i], pad=(0, self.max_transcription_len-len(ret_ctois[i])), value=0) for i in range(length)]\n",
    "        if self.ty in (\"img\", None):\n",
    "            self.ret_images = [torch.load(line_datas[i][\"image_pt_path\"]) for i in range(length)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Different type of individual loaders\n",
    "        if self.ty == \"txt\":\n",
    "            return self.ret_ctoi_paddeds[index]\n",
    "        elif self.ty == \"img\":\n",
    "            return self.ret_images[index]\n",
    "        else:\n",
    "            return self.ret_images[index], self.ret_ctoi_paddeds[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24256\n",
      "lines\n",
      "images\n",
      "both\n",
      "22829 1427\n"
     ]
    }
   ],
   "source": [
    "#line_transcription_dataset = LineDataset(\"./data/lines_improved_recognizer.txt\", ty=\"txt\")\n",
    "#line_image_dataset = LineDataset(\"./data/lines_improved_recognizer.txt\", ty=\"img\")\n",
    "line_dataset = LineDataset(\"./data/lines_improved_recognizer.txt\")\n",
    "print(len(line_dataset))\n",
    "\n",
    "# Don't change this, we want to maintain consistent split\n",
    "torch.manual_seed(12345678)  # DO NOT REMOVE THIS LINE\n",
    "#line_transcription_dataset_train, line_transcription_dataset_val = random_split(line_transcription_dataset, [0.8, 0.2])\n",
    "#line_image_dataset_train, line_image_dataset_val = random_split(line_image_dataset, [0.8, 0.2])\n",
    "line_dataset_train = Subset(line_dataset, range(int(len(line_dataset)*16/17)))\n",
    "line_dataset_val = Subset(line_dataset, range(int(len(line_dataset)*16/17), len(line_dataset)))\n",
    "\n",
    "# To train on a small dataset\n",
    "#line_transcription_dataset_train = Subset(line_transcription_dataset_train, range(64*5))\n",
    "#line_transcription_dataset_val = Subset(line_transcription_dataset_val, range(10))\n",
    "\n",
    "#line_image_dataset_train = Subset(line_image_dataset_train, range(64*5))\n",
    "#line_image_dataset_val = Subset(line_image_dataset_val, range(10))\n",
    "\n",
    "#line_dataset_train = Subset(line_dataset_train, range(19000))\n",
    "#line_dataset_val = Subset(line_dataset_val, range(1000))\n",
    "\n",
    "# line_transcription_dataset_train, line_transcription_dataset_val, _ = random_split(line_transcription_dataset, [0.005, 0.005, 0.99])\n",
    "# line_image_dataset_train, line_image_dataset_val, _ = random_split(line_image_dataset, [0.005, 0.005, 0.99])\n",
    "# line_dataset_train, line_dataset_val = random_split(line_dataset, [0.0025, 0.9975])\n",
    "\n",
    "print(\"lines\")\n",
    "#print(len(line_transcription_dataset_train), len(line_transcription_dataset_val))\n",
    "print(\"images\")\n",
    "#print(len(line_image_dataset_train), len(line_image_dataset_val))\n",
    "print(\"both\")\n",
    "print(len(line_dataset_train), len(line_dataset_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 136.,  356.,  315.,  399.,  445.,  504., 1199., 2049., 3871.,\n",
       "        3494., 4378., 3125., 2014., 1006.,  528.,  287.,   76.,   54.,\n",
       "           9.,   11.]),\n",
       " array([ 4. ,  7.9, 11.8, 15.7, 19.6, 23.5, 27.4, 31.3, 35.2, 39.1, 43. ,\n",
       "        46.9, 50.8, 54.7, 58.6, 62.5, 66.4, 70.3, 74.2, 78.1, 82. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = line_dataset.lines_df[\"transcription_len\"].to_numpy()\n",
    "plt.hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512])\n",
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([22, 67, 66,  1, 58, 47, 49, 51,  6, 59, 47, 57, 55, 60, 53,  1, 55, 65,\n",
       "          1, 48, 71,  1, 60, 61,  1, 59, 51, 47, 60, 65,  1, 47,  1, 58, 61, 65,\n",
       "         66,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " 'But lace-making is by no means a lost')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = line_dataset_train[9995]\n",
    "print(image.shape)\n",
    "plt.title(\"\".join([int_to_char[int(val)] for val in label[label.nonzero()]]))\n",
    "print(image.squeeze(0).shape)\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "label, \"\".join([int_to_char[int(val)] for val in label[label.nonzero()]])\n",
    "# line_dataset.lines_df.iloc[798]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73, 82])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "class Recognizer(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN:\n",
    "    Input with a N x 1 x 32 x 512 image\n",
    "    Output a vector representation of the text size N x 73 x (82*2+1)\n",
    "    Purpose is to recognize the text from the image, to encourage the generator to produce images that are representations of the text\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"recognizer\"\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=8)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(4,2))\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        #self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(4,2))\n",
    "        #xself.bn5 = nn.BatchNorm2d(num_features=128)\n",
    "        #self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(4,2))\n",
    "        #self.bn6 = nn.BatchNorm2d(num_features=256)\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=4, bidirectional=True, batch_first=True, dropout=0.5)\n",
    "        self.dense = nn.Linear(256, 73)\n",
    "        self.dense2 = nn.Linear(505, 82)\n",
    "        \n",
    "        #self.fc = nn.Linear(10, 82)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3)\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img = self.bn1(self.lrelu(self.conv1(img)))\n",
    "        #print(img.shape)\n",
    "        img = self.bn2(self.lrelu(self.conv2(img)))\n",
    "        #print(img.shape)\n",
    "        img = self.bn3(self.lrelu(self.dropout(self.conv3(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn4(self.lrelu(self.dropout(self.conv4(img))))\n",
    "        #print(img.shape)\n",
    "        #img = self.bn5(self.lrelu(self.dropout(self.conv5(img))))\n",
    "        #print(img.shape)\n",
    "        # Collapse \n",
    "        img, _ = torch.max(img, dim=2)\n",
    "        #print(img.shape)\n",
    "        img = img.permute(0, 2, 1)\n",
    "        #print(img.shape)\n",
    "        img, _ = self.lstm(img)\n",
    "        #print(img.shape)\n",
    "        img = self.lrelu(self.dense(img))\n",
    "        #print(img.shape)\n",
    "        img = img.permute(0,2,1)\n",
    "        img = self.lrelu(self.dense2(img))\n",
    "        \n",
    "        #img = self.fc(img)\n",
    "        #print(img.shape)\n",
    "        #print(img.shape)\n",
    "        return img\n",
    "        # img = torch.stack()\n",
    "        # img = self.dense(img)\n",
    "    \n",
    "recog = Recognizer()\n",
    "a =recog(torch.randn((1, 1, 32, 512), dtype=torch.float32))\n",
    "#print(recog)\n",
    "    # TODO: http://www.tbluche.com/files/icdar17_gnn.pdf use \"big architecture\"\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(device, recognizer, val_line_dataset_loader, recognizer_loss_function):\n",
    "    recognizer.eval() \n",
    "    total_loss = 0.0\n",
    "    total_epoch = 0\n",
    "    \n",
    "    for i, (line_image_batch, line_text_batch) in enumerate(val_line_dataset_loader, 0):\n",
    "        line_image_batch = line_image_batch.to(device) \n",
    "        line_text_batch = line_text_batch.to(device)\n",
    "        recognizer_outputs = recognizer(line_image_batch)\n",
    "        recognizer_loss = recognizer_loss_function(F.log_softmax(recognizer_outputs, 1), line_text_batch)\n",
    "        \n",
    "        total_loss += recognizer_loss.item()\n",
    "        total_epoch += 1\n",
    "        \n",
    "    loss = float(total_loss) / (i + 1)\n",
    "    \n",
    "    #print(recognizer_outputs, recognizer_outputs.shape)\n",
    "    #print(torch.argmax(recognizer_outputs, 1), torch.argmax(recognizer_outputs, 1).shape)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_recog_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of the recognizer with character error rate\n",
    "    which is based on edit distance\n",
    "\n",
    "    Params:\n",
    "        preds: a list of prediction strings\n",
    "        targets: a list of target strings\n",
    "\n",
    "    Returns:\n",
    "        An integer, the character error rate average across\n",
    "        all predictions and targets\n",
    "    \"\"\"\n",
    "\n",
    "    cer = CharErrorRate()\n",
    "    return cer(preds, target)\n",
    "\n",
    "def create_strings_from_tensor(int_tensor):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        int_tensor: A shape (N, 82) tensor where each row corresponds to\n",
    "        a integer mapping of a string. Includes padding\n",
    "    \n",
    "    Returns:\n",
    "        A list of N strings\n",
    "    \"\"\"\n",
    "\n",
    "    strings = []\n",
    "    for string_map in int_tensor:\n",
    "        strings.append(\"\".join([int_to_char[int(i)] for i in string_map[string_map != 0]]))\n",
    "    return strings\n",
    "    \n",
    "\n",
    "def get_accuracy(device, recognizer, recognizer_loader):\n",
    "\n",
    "    acc = 0\n",
    "    \n",
    "    for i, (line_image_batch, line_text_batch) in enumerate(recognizer_loader, 0):\n",
    "        line_image_batch = line_image_batch.to(device)\n",
    "        line_text_batch\n",
    "        recognizer_outputs = torch.argmax(recognizer(line_image_batch), 1)\n",
    "        recognizer_pred = create_strings_from_tensor(recognizer_outputs)\n",
    "        \n",
    "        label = create_strings_from_tensor(line_text_batch)\n",
    "        \n",
    "        acc += calculate_recog_accuracy(recognizer_pred, label)\n",
    "        \n",
    "        \n",
    "    return acc / (i+1)\n",
    "        \n",
    "    \n",
    "\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n",
    "\n",
    "def plot_training_curve(path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    \n",
    "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
    "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
    "    \n",
    "    n = len(train_loss) # number of epochs\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Train vs Validation Error\")\n",
    "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend([\"Train Error\", \"Validation Error\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(recognizer, \n",
    "              train_line_dataset, val_line_dataset, \n",
    "              batch_size=64, recognizer_lr=1e-5,\n",
    "              betas=(0, 0.999), num_epochs=30, loss_balancing_alpha=1):\n",
    "    # Note, the generator and discriminator should be spectrally normalized before training\n",
    "    # TODO: load dataloader with batch size batch_size\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device('cpu')\n",
    "    #print(device)\n",
    "    recognizer = recognizer.to(device)\n",
    "    \n",
    "    train_line_dataset_loader = DataLoader(train_line_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_line_dataset_loader = DataLoader(val_line_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #print(len(train_line_dataset_loader))\n",
    "\n",
    "    recognizer_optimizer = optim.Adam(recognizer.parameters(), lr=recognizer_lr)\n",
    "    \n",
    "    recognizer_loss_function = nn.NLLLoss()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(recognizer.parameters(), max_norm=0.5)\n",
    "    recognizer_train_losses = np.zeros(num_epochs)\n",
    "    recognizer_train_accuracies = np.zeros(num_epochs)\n",
    "    recognizer_val_losses = np.zeros(num_epochs)\n",
    "    recognizer_val_accuracies = np.zeros(num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        display_images = []\n",
    "\n",
    "        recognizer_train_loss = 0\n",
    "\n",
    "        for i, (line_image_batch, line_text_batch) in enumerate(train_line_dataset_loader):\n",
    "#             print(\"epoch\", epoch, \"batch\", i)\n",
    "#             print(\"line_image_batch.shape\", line_image_batch.shape)\n",
    "            cur_batch_size, _ = line_text_batch.shape\n",
    "            # print(line_text_batch.shape)\n",
    "\n",
    "#             print(\"line_text_batch.shape\", line_text_batch.shape)\n",
    "            test = line_text_batch[0]\n",
    "            test = test[test.nonzero()]\n",
    "            test = \"\".join([int_to_char[int(i)] for i in test])\n",
    "            line_image_batch = line_image_batch.to(device)\n",
    "            line_text_batch = line_text_batch.to(device)\n",
    "            plt.imshow(line_image_batch[0].cpu().squeeze(0), cmap='gray')\n",
    "            #print(line_text_batch, line_text_batch.shape)\n",
    "            recognizer_outputs = recognizer(line_image_batch)  # Mult factor to incentivize padding\n",
    "   \n",
    "            # print(recognizer_outputs, recognizer_outputs.shape)\n",
    "            # print(line_text_batch, line_text_batch.shape)\n",
    "#             test2 = \"\".join([int_to_char[int(i)] for i in test2])\n",
    "\n",
    "#             Refer to CTC documentation\n",
    "            #line_text_batch_pad_remove = [line_text[line_text.nonzero().squeeze(1)] for line_text in line_text_batch]  # Array of tensors\n",
    "            #target_lengths = torch.tensor([len(line_text_pad_remove) for line_text_pad_remove in line_text_batch_pad_remove])\n",
    "            #target = torch.cat(line_text_batch_pad_remove)\n",
    "            #print(target, target.shape)\n",
    "            #input_lengths = torch.full(size=(cur_batch_size,), fill_value=248)\n",
    "            recognizer_loss = recognizer_loss_function(\n",
    "                # torch.argmax(F.log_softmax(recognizer_outputs, 2), 1),\n",
    "                F.log_softmax(recognizer_outputs, 1),  # Requires number of classes to move from 2nd to 1st dimension after log_softmax\n",
    "                line_text_batch\n",
    "            )\n",
    "            test2 = recognizer_outputs[0,:,:]\n",
    "            test2 = torch.argmax(test2, dim=0)  # Removed 0 dim\n",
    "            test2 = test2[test2.nonzero()]\n",
    "            test2 = \"\".join([int_to_char[int(i)] for i in test2])\n",
    "            \n",
    "\n",
    "            recognizer_loss.backward()\n",
    "            recognizer_optimizer.step()\n",
    "            recognizer_optimizer.zero_grad()\n",
    "    \n",
    "            recognizer_train_loss += recognizer_loss.item()\n",
    "        \n",
    "        print(\"\\t\",test)\n",
    "        print(f\"_{test2}_\")\n",
    "        recognizer_train_losses[epoch] = float(recognizer_train_loss) / (i+1)\n",
    "        \n",
    "        recognizer.eval()\n",
    "        recognizer_val_losses[epoch] = evaluate(device, recognizer, val_line_dataset_loader, recognizer_loss_function)\n",
    "        recognizer.train()\n",
    "        \n",
    "        recognizer_train_accuracies[epoch] = get_accuracy(device, recognizer, train_line_dataset_loader)\n",
    "        recognizer_val_accuracies[epoch]= get_accuracy(device, recognizer, val_line_dataset_loader)\n",
    "        \n",
    "        print((\"Epoch {}: Train loss: {} | Train Accuracy: {} | \"+\n",
    "            \" Validation loss: {} | Validation Accuracy: {}\").format(\n",
    "                    epoch + 1,\n",
    "                    recognizer_train_losses[epoch],\n",
    "                    recognizer_train_accuracies[epoch],\n",
    "                    recognizer_val_losses[epoch],\n",
    "                    recognizer_val_accuracies[epoch]))\n",
    "\n",
    "        model_path = get_model_name(recognizer.name, batch_size, recognizer_lr, epoch)\n",
    "        torch.save(recognizer.state_dict(), os.path.join(\"./recognizers\", model_path))\n",
    "        model_path_const_batch = get_model_name(recognizer.name, batch_size, recognizer_lr, -1)\n",
    "\n",
    "        np.savetxt(\"./recognizers/{}_train_loss.csv\".format(model_path_const_batch), recognizer_train_losses)\n",
    "        np.savetxt(\"./recognizers/{}_val_loss.csv\".format(model_path_const_batch),  recognizer_val_losses)\n",
    "        np.savetxt(\"./recognizers/{}_train_acc.csv\".format(model_path_const_batch), recognizer_train_accuracies)\n",
    "        np.savetxt(\"./recognizers/{}_val_acc.csv\".format(model_path_const_batch), recognizer_val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_curve(\"./recognizers/model_recognizer_bs8_lr0.0005_epoch-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Main Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Hyperparameters to Tune\n",
    "- Dimension of text embedding, we can start with 128, 256, or 512 and increase it later on.\n",
    "- Dataset of training. If the model does not converge, it is likely we will have to manually select example images that have similar writing style.\n",
    "- Learning rate\n",
    "- Balancing the effect of recognizer and discriminator\n",
    "\n",
    "- Generator Networks:\n",
    "  - ResNetUp\n",
    "    - Should the bias be False? Or can it be True?\n",
    "      - conv1 probably don't, since it is batch-normalized right after\n",
    "      - but what about conv2?\n",
    "  - Conditional Batch Norm\n",
    "  - Number of filters in each resnet block\n",
    "\n",
    "LSTM hidden layers should increase, hidden size should increase. \n",
    "- because our text is longer. \n",
    "\n",
    "- Discriminator Networks:\n",
    "  - ResNetDown\n",
    "    - Still if bias should be False?\n",
    "    - LeakyReLU slope\n",
    "  - ResNet\n",
    "    - bias?\n",
    "    - leakyReLU slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m recognizer \u001b[39m=\u001b[39m Recognizer()\n\u001b[1;32m      2\u001b[0m \u001b[39m# generator = load_model(generator, \"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)_generator_epoch9.pt\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# generator, encoder, discriminator = load_models_of_same_batch(generator, encoder, discriminator, filename_prefix=\"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)\", epoch_number=9)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train(recognizer\u001b[39m=\u001b[39;49mrecognizer, \n\u001b[1;32m      6\u001b[0m               train_line_dataset\u001b[39m=\u001b[39;49mline_dataset_train, val_line_dataset\u001b[39m=\u001b[39;49mline_dataset_val, \n\u001b[1;32m      7\u001b[0m               batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, recognizer_lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m               betas\u001b[39m=\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39m0.999\u001b[39;49m), num_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, loss_balancing_alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[27], line 47\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(recognizer, train_line_dataset, val_line_dataset, batch_size, recognizer_lr, betas, num_epochs, loss_balancing_alpha)\u001b[0m\n\u001b[1;32m     45\u001b[0m             plt\u001b[39m.\u001b[39mimshow(line_image_batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m             \u001b[39m#print(line_text_batch, line_text_batch.shape)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m             recognizer_outputs \u001b[39m=\u001b[39m recognizer(line_image_batch)  \u001b[39m# Mult factor to incentivize padding\u001b[39;00m\n\u001b[1;32m     49\u001b[0m             \u001b[39m# print(recognizer_outputs, recognizer_outputs.shape)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             \u001b[39m# print(line_text_batch, line_text_batch.shape)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m#             test2 = \"\".join([int_to_char[int(i)] for i in test2])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[39m#print(target, target.shape)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m             \u001b[39m#input_lengths = torch.full(size=(cur_batch_size,), fill_value=248)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m             recognizer_loss \u001b[39m=\u001b[39m recognizer_loss_function(\n\u001b[1;32m     60\u001b[0m                 \u001b[39m# torch.argmax(F.log_softmax(recognizer_outputs, 2), 1),\u001b[39;00m\n\u001b[1;32m     61\u001b[0m                 F\u001b[39m.\u001b[39mlog_softmax(recognizer_outputs, \u001b[39m1\u001b[39m),  \u001b[39m# Requires number of classes to move from 2nd to 1st dimension after log_softmax\u001b[39;00m\n\u001b[1;32m     62\u001b[0m                 line_text_batch\n\u001b[1;32m     63\u001b[0m             )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 51\u001b[0m, in \u001b[0;36mRecognizer.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     49\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39m#print(img.shape)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m img, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(img)\n\u001b[1;32m     52\u001b[0m \u001b[39m#print(img.shape)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(img))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recognizer = Recognizer()\n",
    "# generator = load_model(generator, \"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)_generator_epoch9.pt\")\n",
    "# generator, encoder, discriminator = load_models_of_same_batch(generator, encoder, discriminator, filename_prefix=\"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)\", epoch_number=9)\n",
    "\n",
    "train(recognizer=recognizer, \n",
    "              train_line_dataset=line_dataset_train, val_line_dataset=line_dataset_val, \n",
    "              batch_size=8, recognizer_lr=1e-3,\n",
    "              betas=(0, 0.999), num_epochs=500, loss_balancing_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = line_dataset_train[0]\n",
    "print(image.shape)\n",
    "plt.title(\"\".join([int_to_char[int(val)] for val in label[label.nonzero()]]))\n",
    "print(image.squeeze(0).shape)\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "label, \"\".join([int_to_char[int(val)] for val in label[label.nonzero()]])\n",
    "\n",
    "print(torch.softmax(recognizer(image.unsqueeze(0)), 1), torch.softmax(recognizer(image.unsqueeze(0)), 1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
