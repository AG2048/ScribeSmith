{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizer for Handwritten Text Synthesis GAN\n",
    "\n",
    "This model will consist of 4 major networks, following the general architecture of an GAN.\n",
    "\n",
    "1. Encoder: Produces an embedding that will be concatenated with the noise vector.\n",
    "2. Generator: Taking noise vector as input and the text embedding to produce an 128x2048 image.\n",
    "3. Discriminator: Trained alternating with generator input and ground-truth input, binary classification real or fake.\n",
    "4. Recognizer: Taking image as input, produce a vector representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/aps360/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_fidelity\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torch.nn.utils.spectral_norm import spectral_norm\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, Subset, random_split\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.text import CharErrorRate\n",
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Grayscale, Resize, ToTensor, ToPILImage\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (Run once only to format data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_HEIGHT = 32\n",
    "SCALE_WIDTH = SCALE_HEIGHT*16\n",
    "\n",
    "def preprocess_lines(data_root):\n",
    "    \"\"\"\n",
    "    Creates a new `.txt` file `lines_improved.txt` that will be used\n",
    "    for querying. This new `.txt` file contains all info necessary\n",
    "    for the functionality of this project.\n",
    "    \"\"\"\n",
    "\n",
    "    original_path = os.path.join(data_root, \"lines.txt\")\n",
    "    improved_path = os.path.join(data_root, \"lines_improved.txt\")\n",
    "    fi = open(improved_path, \"w\")\n",
    "\n",
    "    # Some variables for tracking\n",
    "    num_samples = 0\n",
    "    valid_samples = 0\n",
    "    \n",
    "    # Loop through \"lines.txt\"\n",
    "    with open(original_path, \"r\") as fo:\n",
    "        headers = [\"image_id\", \"image_path\", \"image_pt_path\", \"graylevel\", \"original_height\", \"original_width\", \"transcription\", \"transcription_len\"]\n",
    "\n",
    "        # First write the headers at the top of the file\n",
    "        fi.writelines(\"\\t\".join(headers) + \"\\n\")\n",
    "\n",
    "        # Skip the intro stuff\n",
    "        for line in fo.readlines():\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            # Valid lines, not the intro_text\n",
    "            line_items = line.strip().split(\" \")  # `strip()` to remove newlines\n",
    "\n",
    "            # The actual items (we extract the important ones)\n",
    "            image_id = line_items[0]\n",
    "            status = line_items[1]\n",
    "            graylevel = int(line_items[2])\n",
    "            transcription = \" \".join(line_items[8:])  # Some data has whitespace, we join string till the end\n",
    "\n",
    "            # Skip error images\n",
    "            if status == \"err\":\n",
    "                continue\n",
    "        \n",
    "            # Alphanumeric + common punctuation regex\n",
    "            # Returns None if no match\n",
    "            # 26 + 26 + 10 + 9 + 1 = 72\n",
    "            # Spaces might be included as well\n",
    "            # Punctuation include , ! ? ' \" , : ; -\n",
    "            if re.fullmatch(\"[a-zA-Z0-9.!?'\\\",:;| -]*\", transcription) is None:\n",
    "                continue\n",
    "\n",
    "            # Now we have valid transcription\n",
    "            num_samples += 1\n",
    "\n",
    "            # We get the `.png` image path\n",
    "            inp = image_id.split(\"-\")  # `inp` stands for image name parts\n",
    "            image_path_head = os.path.join(data_root, \"lines\", inp[0], f\"{inp[0]}-{inp[1]}\")\n",
    "            image_path_tail = f\"{image_id}.png\"\n",
    "            image_path = os.path.join(image_path_head, image_path_tail)\n",
    "            \n",
    "            # Read image, gets its dimensions, perform processing operations, and other stuff\n",
    "            tmp_image = cv.imread(os.path.join(image_path_head, image_path_tail), cv.IMREAD_GRAYSCALE)  # Removes the channel dimension\n",
    "            height, width = tmp_image.shape\n",
    "\n",
    "            # Scaling calculations\n",
    "            # If width * scale >= desired length (>= to be safe)\n",
    "            # Condition here to speed up overall processing time\n",
    "            if width * (SCALE_HEIGHT/height) >= SCALE_WIDTH:\n",
    "                continue\n",
    "\n",
    "            resized_tensor = process_image(tmp_image, graylevel)\n",
    "            image_pt_path = os.path.join(image_path_head, f\"{image_id}.pt\")\n",
    "            torch.save(resized_tensor, image_pt_path)\n",
    "\n",
    "            # A fully valid image\n",
    "            # Separate by underscores because `transcription` has spaces so we can't split by spaces\n",
    "            fi.writelines(f\"{image_id}\\t{image_path}\\t{image_pt_path}\\t{graylevel}\\t{height}\\t{width}\\t{transcription}\\t{len(transcription)}\\n\")\n",
    "            valid_samples += 1\n",
    "        \n",
    "        fi.close()\n",
    "    \n",
    "    print(\"# samples:\", num_samples)\n",
    "    print(\"Valid samples:\", valid_samples)\n",
    "\n",
    "\n",
    "def process_image(cv_image, graylevel):\n",
    "    \"\"\"\n",
    "    Takes in a grayscale image that OpenCV read of shape (H, W) of type uint8\n",
    "    Returns a PyTorch tensor of shape (1, 32, W'), where W' is the scaled width\n",
    "    This tensor is padded and effectively thresholded\n",
    "    \"\"\"\n",
    "\n",
    "    # Scaling factor\n",
    "    height, width = cv_image.shape\n",
    "    scale = SCALE_HEIGHT/height\n",
    "    scaled_width = int(width*scale)\n",
    "\n",
    "    # Trick here is to apply threshold before resize and padding\n",
    "    # This allows OpenCV resizing to create a cleaner output image\n",
    "    # 2nd return value is the thresholded image\n",
    "    output = cv.threshold(cv_image, graylevel, 255, cv.THRESH_BINARY)[1]\n",
    "\n",
    "    # INTER_AREA recommended for sizing down\n",
    "    output = cv.resize(output, (scaled_width, SCALE_HEIGHT), interpolation=cv.INTER_AREA)\n",
    "\n",
    "    # Turn it back to a tensor and map to [0, 1]\n",
    "    output = torch.from_numpy(output).unsqueeze(0).type(torch.float32)\n",
    "    output = (output-output.min()) / (output.max()-output.min())\n",
    "    \n",
    "    # Add padding\n",
    "    _, _, resized_height = output.shape\n",
    "    padding_to_add = SCALE_WIDTH - resized_height\n",
    "    output = F.pad(output, (0, padding_to_add), value=1.0)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Uncomment this if your data isn't processed yet\n",
    "# preprocess_lines(\"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Dict (Run everytime before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted by ascii code\n",
    "valid = [\n",
    "    ' ', '!', '\"', \"'\", ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "    ':', ';', '?', \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
    "]\n",
    "# Enumerate from 1 to save space for padding\n",
    "# Reserve 0 for CTC blank\n",
    "char_to_int = {v: i for i, v in enumerate(valid, 1)}\n",
    "int_to_char = {i: v for i, v in enumerate(valid, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineDataset(Dataset):\n",
    "    def __init__(self, lines_improved_dir, ty=None):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            lines_improved_dir: path to the `lines_improved.txt` file\n",
    "            ty: type of the dataset \"txt\", \"img\" for text dataset or image dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dataframe containing the stuff in `lines_improved.txt`\n",
    "        self.lines_df = pd.read_csv(lines_improved_dir, sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "        # Class properties\n",
    "        self.ty = ty  # Type of dataset (lines, images, or both)\n",
    "        self.max_transcription_len = max(self.lines_df[\"transcription_len\"])\n",
    "\n",
    "        # Temp variables...\n",
    "        length = self.lines_df.shape[0]\n",
    "        line_datas = self.lines_df.iloc\n",
    "        ret_texts = [line_datas[i][\"transcription\"].replace('|', ' ') for i in range(length)]\n",
    "        ret_ctois = [torch.tensor([char_to_int[char] for char in ret_texts[i]]) for i in range(length)]\n",
    "\n",
    "        # ...for the important data\n",
    "        if self.ty in (\"txt\", None):  # Added this condition to speed thigns up if only text\n",
    "            self.ret_ctoi_paddeds = [F.pad(ret_ctois[i], pad=(0, self.max_transcription_len-len(ret_ctois[i])), value=0) for i in range(length)]\n",
    "        if self.ty in (\"img\", None):\n",
    "            self.ret_images = [torch.load(line_datas[i][\"image_pt_path\"]) for i in range(length)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Different type of individual loaders\n",
    "        if self.ty == \"txt\":\n",
    "            return self.ret_ctoi_paddeds[index]\n",
    "        elif self.ty == \"img\":\n",
    "            return self.ret_images[index]\n",
    "        else:\n",
    "            return self.ret_images[index], self.ret_ctoi_paddeds[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "320 10\n",
      "images\n",
      "320 10\n",
      "both\n",
      "1000 200\n"
     ]
    }
   ],
   "source": [
    "line_transcription_dataset = LineDataset(\"./data/lines_improved.txt\", ty=\"txt\")\n",
    "line_image_dataset = LineDataset(\"./data/lines_improved.txt\", ty=\"img\")\n",
    "line_dataset = LineDataset(\"./data/lines_improved.txt\")\n",
    "\n",
    "# Don't change this, we want to maintain consistent split\n",
    "torch.manual_seed(12345678)  # DO NOT REMOVE THIS LINE\n",
    "line_transcription_dataset_train, line_transcription_dataset_val = random_split(line_transcription_dataset, [0.8, 0.2])\n",
    "line_image_dataset_train, line_image_dataset_val = random_split(line_image_dataset, [0.8, 0.2])\n",
    "line_dataset_train, line_dataset_val = random_split(line_dataset, [0.8, 0.2])\n",
    "\n",
    "# To train on a small dataset\n",
    "line_transcription_dataset_train = Subset(line_transcription_dataset_train, range(64*5))\n",
    "line_transcription_dataset_val = Subset(line_transcription_dataset_val, range(10))\n",
    "\n",
    "line_image_dataset_train = Subset(line_image_dataset_train, range(64*5))\n",
    "line_image_dataset_val = Subset(line_image_dataset_val, range(10))\n",
    "\n",
    "line_dataset_train = Subset(line_dataset_train, range(1000))\n",
    "line_dataset_val = Subset(line_dataset_val, range(200))\n",
    "\n",
    "# line_transcription_dataset_train, line_transcription_dataset_val, _ = random_split(line_transcription_dataset, [0.005, 0.005, 0.99])\n",
    "# line_image_dataset_train, line_image_dataset_val, _ = random_split(line_image_dataset, [0.005, 0.005, 0.99])\n",
    "# line_dataset_train, line_dataset_val = random_split(line_dataset, [0.0025, 0.9975])\n",
    "\n",
    "print(\"lines\")\n",
    "print(len(line_transcription_dataset_train), len(line_transcription_dataset_val))\n",
    "print(\"images\")\n",
    "print(len(line_image_dataset_train), len(line_image_dataset_val))\n",
    "print(\"both\")\n",
    "print(len(line_dataset_train), len(line_dataset_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512])\n",
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([66, 61,  1,  9, 17,  1,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " 'to 19 .')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = line_dataset_train[0]\n",
    "print(image.shape)\n",
    "plt.title(\"\".join([int_to_char[int(val)] for val in label[label.nonzero()]]))\n",
    "print(image.squeeze(0).shape)\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "label, \"\".join([int_to_char[int(val)] for val in label[label.nonzero()]])\n",
    "# line_dataset.lines_df.iloc[798]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Key Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognizer Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recog_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of the recognizer with character error rate\n",
    "    which is based on edit distance\n",
    "\n",
    "    Params:\n",
    "        preds: a list of prediction strings\n",
    "        targets: a list of target strings\n",
    "\n",
    "    Returns:\n",
    "        An integer, the character error rate average across\n",
    "        all predictions and targets\n",
    "    \"\"\"\n",
    "\n",
    "    cer = CharErrorRate(preds, target)\n",
    "    return cer\n",
    "\n",
    "\n",
    "def create_strings_from_tensor(int_tensor):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        int_tensor: A shape (N, 82) tensor where each row corresponds to\n",
    "        a integer mapping of a string. Includes padding\n",
    "    \n",
    "    Returns:\n",
    "        A list of N strings\n",
    "    \"\"\"\n",
    "\n",
    "    strings = []\n",
    "    for string_map in int_tensor:\n",
    "        strings.append(\"\".join([int_to_char[int(i)] for i in string_map[string_map != 0]]))\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(recognizer, \n",
    "              train_line_dataset, val_line_dataset, \n",
    "              batch_size=64, recognizer_lr=1e-5,\n",
    "              betas=(0, 0.999), num_epochs=30, loss_balancing_alpha=1):\n",
    "    # Note, the generator and discriminator should be spectrally normalized before training\n",
    "    # TODO: load dataloader with batch size batch_size\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device('cpu')\n",
    "    #print(device)\n",
    "    recognizer = recognizer.to(device)\n",
    "    \n",
    "    train_line_dataset_loader = DataLoader(train_line_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_line_dataset_loader = DataLoader(val_line_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #print(len(train_line_dataset_loader))\n",
    "\n",
    "    recognizer_optimizer = optim.Adam(recognizer.parameters(), lr=recognizer_lr)\n",
    "    \n",
    "    recognizer_loss_function = nn.NLLLoss()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(recognizer.parameters(), max_norm=0.5)\n",
    "    recognizer_train_losses = []\n",
    "    recognizer_train_accuracies = []\n",
    "    recognizer_val_losses = []\n",
    "    recognizer_val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        display_images = []\n",
    "\n",
    "        recognizer_train_loss = 0\n",
    "        recognizer_train_accuracy = 0\n",
    "\n",
    "        for i, (line_image_batch, line_text_batch) in enumerate(train_line_dataset_loader):\n",
    "#             print(\"epoch\", epoch, \"batch\", i)\n",
    "#             print(\"line_image_batch.shape\", line_image_batch.shape)\n",
    "            cur_batch_size, _ = line_text_batch.shape\n",
    "            # print(line_text_batch.shape)\n",
    "\n",
    "#             print(\"line_text_batch.shape\", line_text_batch.shape)\n",
    "            test = line_text_batch[0]\n",
    "            test = test[test.nonzero()]\n",
    "            test = \"\".join([int_to_char[int(i)] for i in test])\n",
    "            line_image_batch = line_image_batch.to(device)\n",
    "            line_text_batch = line_text_batch.to(device)\n",
    "            plt.imshow(line_image_batch[0].cpu().squeeze(0), cmap='gray')\n",
    "            #print(line_text_batch, line_text_batch.shape)\n",
    "            recognizer_outputs = recognizer(line_image_batch)  # Mult factor to incentivize padding\n",
    "   \n",
    "            # print(recognizer_outputs, recognizer_outputs.shape)\n",
    "            # print(line_text_batch, line_text_batch.shape)\n",
    "#             test2 = \"\".join([int_to_char[int(i)] for i in test2])\n",
    "\n",
    "#             Refer to CTC documentation\n",
    "            #line_text_batch_pad_remove = [line_text[line_text.nonzero().squeeze(1)] for line_text in line_text_batch]  # Array of tensors\n",
    "            #target_lengths = torch.tensor([len(line_text_pad_remove) for line_text_pad_remove in line_text_batch_pad_remove])\n",
    "            #target = torch.cat(line_text_batch_pad_remove)\n",
    "            #print(target, target.shape)\n",
    "            #input_lengths = torch.full(size=(cur_batch_size,), fill_value=248)\n",
    "            recognizer_loss = recognizer_loss_function(\n",
    "                # torch.argmax(F.log_softmax(recognizer_outputs, 2), 1),\n",
    "                F.log_softmax(recognizer_outputs, 1),  # Requires number of classes to move from 2nd to 1st dimension after log_softmax\n",
    "                line_text_batch\n",
    "            )\n",
    "            test2 = recognizer_outputs[0,:,:]\n",
    "            test2 = torch.argmax(test2, dim=0)  # Removed 0 dim\n",
    "            test2 = test2[test2.nonzero()]\n",
    "            test2 = \"\".join([int_to_char[int(i)] for i in test2])\n",
    "            \n",
    "\n",
    "            recognizer_loss.backward()\n",
    "            recognizer_optimizer.step()\n",
    "            recognizer_optimizer.zero_grad()\n",
    "            # print(recognizer_loss)\n",
    "        \n",
    "        print(test)\n",
    "        print(f\"_{test2}_\")\n",
    "            # recognizer_train_loss += recognizer_loss\n",
    "        print(recognizer_loss)\n",
    "        \n",
    "        recognizer_val_loss = 9999\n",
    "\n",
    "        print(f\"Epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Main Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizer(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(64, 128, kernel_size=(4, 2), stride=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm): LSTM(128, 128, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (dense): Linear(in_features=256, out_features=73, bias=True)\n",
      "  (dense2): Linear(in_features=248, out_features=82, bias=True)\n",
      "  (lrelu): LeakyReLU(negative_slope=0.01)\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.2, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73, 82])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "class Recognizer(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN:\n",
    "    Input with a N x 1 x 32 x 512 image\n",
    "    Output a vector representation of the text size N x 73 x (82*2+1)\n",
    "    Purpose is to recognize the text from the image, to encourage the generator to produce images that are representations of the text\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"recognizer\"\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=8)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(4, 2))\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=128)\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, num_layers=3, bidirectional=True, batch_first=True, dropout=0.5)\n",
    "        self.dense = nn.Linear(256, 73)\n",
    "        self.dense2 = nn.Linear(248, 82)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img = self.bn1(self.lrelu(self.maxpool(self.conv1(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn2(self.lrelu(self.conv2(img)))\n",
    "        #print(img.shape)\n",
    "        img = self.bn3(self.lrelu(self.dropout(self.conv3(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn4(self.lrelu(self.dropout(self.conv4(img))))\n",
    "        #print(img.shape)\n",
    "        img = self.bn5(self.lrelu(self.dropout(self.conv5(img))))\n",
    "        #print(img.shape)\n",
    "        # Collapse \n",
    "        img, _ = torch.max(img, dim=2)\n",
    "        #print(img.shape)\n",
    "        img = img.permute(0, 2, 1)\n",
    "        #print(img.shape)\n",
    "        img, _ = self.lstm(img)\n",
    "        #print(img.shape)\n",
    "        img = self.lrelu(self.dense(img))\n",
    "        #print(img.shape)\n",
    "        img = img.permute(0,2,1)\n",
    "        img = self.dense2(img)\n",
    "        #print(img.shape)\n",
    "        #print(img.shape)\n",
    "        return img\n",
    "        # img = torch.stack()\n",
    "        # img = self.dense(img)\n",
    "        \n",
    "    \n",
    "recog = Recognizer()\n",
    "a =recog(torch.randn((1, 1, 32, 512), dtype=torch.float32))\n",
    "print(recog)\n",
    "    # TODO: http://www.tbluche.com/files/icdar17_gnn.pdf use \"big architecture\"\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Hyperparameters to Tune\n",
    "- Dimension of text embedding, we can start with 128, 256, or 512 and increase it later on.\n",
    "- Dataset of training. If the model does not converge, it is likely we will have to manually select example images that have similar writing style.\n",
    "- Learning rate\n",
    "- Balancing the effect of recognizer and discriminator\n",
    "\n",
    "- Generator Networks:\n",
    "  - ResNetUp\n",
    "    - Should the bias be False? Or can it be True?\n",
    "      - conv1 probably don't, since it is batch-normalized right after\n",
    "      - but what about conv2?\n",
    "  - Conditional Batch Norm\n",
    "  - Number of filters in each resnet block\n",
    "\n",
    "LSTM hidden layers should increase, hidden size should increase. \n",
    "- because our text is longer. \n",
    "\n",
    "- Discriminator Networks:\n",
    "  - ResNetDown\n",
    "    - Still if bias should be False?\n",
    "    - LeakyReLU slope\n",
    "  - ResNet\n",
    "    - bias?\n",
    "    - leakyReLU slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shops at the heart of the\n",
      "__\n",
      "tensor(2.7332, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 0\n",
      "time . Confusion of the original issue\n",
      "__\n",
      "tensor(1.9306, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 1\n",
      "The truth is that good food offers a\n",
      "__\n",
      "tensor(1.8594, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 2\n",
      "some 2,000 delegates , the biggest gathering since 1958\n",
      "__\n",
      "tensor(1.8427, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 3\n",
      "people .\n",
      "__\n",
      "tensor(1.8258, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 4\n",
      "whom Anglesey consulted in May 1834 .\n",
      "__\n",
      "tensor(1.6605, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 5\n",
      "It is impossible for Labour's new Defence state-\n",
      "__\n",
      "tensor(1.7087, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 6\n",
      "in response to the Budgette appeal .\n",
      "__\n",
      "tensor(1.7690, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 7\n",
      "Soviet Union has them .\n",
      "__\n",
      "tensor(1.8499, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 8\n",
      "flower in a cultural desert . \" Now , me - I 'm\n",
      "__\n",
      "tensor(1.8481, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 9\n",
      "offer the Government an easy passage for such\n",
      "__\n",
      "tensor(1.8236, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 10\n",
      "her slatternly , promiscuous mother . In such\n",
      "__\n",
      "tensor(1.7984, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 11\n",
      "agree . The Labour Party opposed Thor missiles , because ,\n",
      "__\n",
      "tensor(1.8330, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 12\n",
      "him go , unable to speak , she\n",
      "__\n",
      "tensor(1.8174, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 13\n",
      "almost cranky . '\n",
      "__\n",
      "tensor(1.7786, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 14\n",
      "who was still repeating in sing-song :\n",
      "_            _\n",
      "tensor(1.8940, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 15\n",
      "morning to retire as soon as it seemed\n",
      "_                              _\n",
      "tensor(1.7845, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 16\n",
      "It would be safer under lock and key\n",
      "_ e                              _\n",
      "tensor(1.6895, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 17\n",
      "frowning face as she turned the\n",
      "_                            _\n",
      "tensor(1.6815, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 18\n",
      "you are looking for someone to love \" .\n",
      "_                               _\n",
      "tensor(1.7306, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 19\n",
      "wrote , ' is arrived , which is a great resource . Vesuvius\n",
      "_                                      _\n",
      "tensor(1.8039, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 20\n",
      "But there is heart in the telling , and an\n",
      "_                                          _\n",
      "tensor(1.7808, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 21\n",
      "above the boney knob which landmarked the cervical\n",
      "_                                         _\n",
      "tensor(1.8044, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 22\n",
      "All types of trader have been encouraged ,\n",
      "_ e                             _\n",
      "tensor(1.5744, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 23\n",
      "five thousand at least . ' He felt in his jacket pocket\n",
      "_ e                                         _\n",
      "tensor(1.7957, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 24\n",
      "a boy , a cheerful , good-natured\n",
      "_ee                       _\n",
      "tensor(1.5846, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 25\n",
      "enumeration is the household schedule .\n",
      "_ee                                 _\n",
      "tensor(1.5659, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 26\n",
      "exactly what you were doing that\n",
      "_ee                        _\n",
      "tensor(1.6440, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 27\n",
      "absolutely beastly , and I can't bear to think\n",
      "_ee                                        _\n",
      "tensor(1.7930, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 28\n",
      "amount of rest seems to make any difference . Sleep , to be\n",
      "_aa                                             _\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 29\n",
      "for herself ; we would be altogether clearer\n",
      "_eo                                         _\n",
      "tensor(1.5179, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 30\n",
      "out of operation - in theory , at\n",
      "_eee  e                    _\n",
      "tensor(1.5635, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 31\n",
      "prosperity tomorrow . BERTRAND RUSSELL ,\n",
      "_eh                                  _\n",
      "tensor(1.6249, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 32\n",
      "were lots of children there , and we had\n",
      "_ee                                _\n",
      "tensor(1.5353, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 33\n",
      "will go . The main topic under review is\n",
      "_hh                                    _\n",
      "tensor(1.5562, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 34\n",
      "to meet head-on the biggest challenge to\n",
      "_eh                                     _\n",
      "tensor(1.5666, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 35\n",
      "thrust out , arms dangling loosely .\n",
      "_oo                               _\n",
      "tensor(1.5361, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 36\n",
      "Monday to Friday were days one\n",
      "_oo                          _\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 37\n",
      "boy . He settled me into the car\n",
      "_hh                              _\n",
      "tensor(1.6619, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 38\n",
      "forty and had written Hamlet two years\n",
      "_ah                                     _\n",
      "tensor(1.6017, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 39\n",
      "Father to drive along that quiet stretch of\n",
      "_io                                   _\n",
      "tensor(1.6873, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 40\n",
      "fish and the gentle putter of the engine\n",
      "_oo                                     _\n",
      "tensor(1.5425, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 41\n",
      "law , always comically grotesque ; they were\n",
      "_ee                                        _\n",
      "tensor(1.5317, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 42\n",
      "back to England , and returned to Rome for\n",
      "_th                                    _\n",
      "tensor(1.5968, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 43\n",
      "peace of mind ? Philip put out\n",
      "_ie                              _\n",
      "tensor(1.5062, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 44\n",
      "' What a frightful event ! ' he wrote . ' I tremble !\n",
      "_ah                                             _\n",
      "tensor(1.5945, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 45\n",
      "to the preparations for launching their\n",
      "_aa                              _\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 46\n",
      "\" Werewolves \" .\n",
      "_ao        _\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 47\n",
      "talks with Mr. Krushchov this evening .\n",
      "_ah                                      _\n",
      "tensor(1.5887, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 48\n",
      "to go , was left almost alone in the\n",
      "_oo                       _\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 49\n",
      "in response to the Budgette appeal .\n",
      "_aa                                  _\n",
      "tensor(1.5063, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 50\n",
      "moment in disgust . She was fully aware that Gavin\n",
      "_oo                                              _\n",
      "tensor(1.5581, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 51\n",
      "expression appears to have been framed in\n",
      "_aa                                   _\n",
      "tensor(1.5660, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 52\n",
      "who was still repeating in sing-song :\n",
      "_ah                              _\n",
      "tensor(1.6269, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 53\n",
      "off it , \" said Bawley . \" The proprietor of the Daily\n",
      "_ah                                             _\n",
      "tensor(1.5269, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 54\n",
      "to give the system a trial , adding that it was being\n",
      "_ o                                              _\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 55\n",
      "THE Palace cinema at Buckley , near Chester , will be\n",
      "_ah                                                  _\n",
      "tensor(1.6589, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 56\n",
      "rough country , sliding on shale , climbing down\n",
      "_ao                                       _\n",
      "tensor(1.5197, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 57\n",
      "surroundings she learns sex is something\n",
      "_ph                                    _\n",
      "tensor(1.5859, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 58\n",
      "left , Milan . The directional angle of the\n",
      "_aa                                      _\n",
      "tensor(1.6351, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 59\n",
      "for a more accurate distribution of\n",
      "_ao                                 _\n",
      "tensor(1.4932, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 60\n",
      "fore ! ' After the curry , I wanted only to go upstairs to\n",
      "_To                                                  _\n",
      "tensor(1.6803, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 61\n",
      "had had the slightest effect .\n",
      "_ao                       _\n",
      "tensor(1.4940, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 62\n",
      "thought of a fire ... .\n",
      "_oo                _\n",
      "tensor(1.5858, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 63\n",
      "other hand , there is really no replacement\n",
      "_ o                                   _\n",
      "tensor(1.6455, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 64\n",
      "moment in disgust . She was fully aware that Gavin\n",
      "_ah                                                 _\n",
      "tensor(1.5494, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 65\n",
      "classes in the early 19th century which\n",
      "_to                                        _\n",
      "tensor(1.5925, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 66\n",
      "' but he appears to despair of ever being cured . '\n",
      "_ o                                             _\n",
      "tensor(1.5569, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 67\n",
      "place agree with me better than Naples . The journey\n",
      "_aa                                              _\n",
      "tensor(1.7056, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 68\n",
      "could see 3anudder 3t'ing , \" he went on in a\n",
      "_ae                                       _\n",
      "tensor(1.5023, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 69\n",
      "consulted in May 1834 .\n",
      "_oo               _\n",
      "tensor(1.5262, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 70\n",
      "robe that each generation wears in turn -\n",
      "_oo                                   _\n",
      "tensor(1.5543, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 71\n",
      "and Simone go through the doorway that led\n",
      "_Th                                           _\n",
      "tensor(1.4695, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 72\n",
      "After what seemed an undue period of repetition , the voice\n",
      "_Bh                                                      _\n",
      "tensor(1.6858, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 73\n",
      "developed by a firm specialising in electronics\n",
      "_ao                                          _\n",
      "tensor(1.6198, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 74\n",
      "success in France and Italy , and that\n",
      "_ao                                  _\n",
      "tensor(1.6876, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 75\n",
      "chapter in the history of Anglesey's unceasing\n",
      "_to   e                                     _\n",
      "tensor(1.5025, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 76\n",
      "studied under its founder , the aged\n",
      "_to                               _\n",
      "tensor(1.5633, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 77\n",
      "relief flooding over him . ' Kitty ... I 'm sorry ... . '\n",
      "_Bh                                                  _\n",
      "tensor(1.5256, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 78\n",
      "Only Mr. Lucas's actions , therefore , arose\n",
      "_Te                                           _\n",
      "tensor(1.4530, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 79\n",
      "agree . The Labour Party opposed Thor missiles , because ,\n",
      "_te                                                _\n",
      "tensor(1.6749, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 80\n",
      "and the latest report I have is that\n",
      "_aee                               _\n",
      "tensor(1.6257, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 81\n",
      "Graybury is one of Mr. Hewson's most\n",
      "_te                              _\n",
      "tensor(1.5929, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 82\n",
      "hut had recently been cleaned and\n",
      "_te                              _\n",
      "tensor(1.5382, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 83\n",
      "' but he appears to despair of ever being cured . '\n",
      "_th                                          _\n",
      "tensor(1.5734, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 84\n",
      "equally familiar hoops to mild laughter .\n",
      "_ah                                      _\n",
      "tensor(1.5608, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 85\n",
      "whose presence I could almost smell ,\n",
      "_te                               _\n",
      "tensor(1.5906, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 86\n",
      "to switch on the lights ; there was no colour -\n",
      "_Ta                                         _\n",
      "tensor(1.4881, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 87\n",
      "who was to become a very intimate friend , and I was\n",
      "_th                                                _\n",
      "tensor(1.5877, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 88\n",
      "that Weaver once had Communist affiliations .\n",
      "_To                                         _\n",
      "tensor(1.4370, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 89\n",
      "he waited . The bus stop was a deserted island on an empty street .\n",
      "_an                                                      _\n",
      "tensor(1.6611, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 90\n",
      "\" Can't go lighting bonfires on this bus , \"\n",
      "_bh                                    _\n",
      "tensor(1.5854, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 91\n",
      "Instead , the kings will remain in London\n",
      "_toe  e                           e     _\n",
      "tensor(1.5647, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 92\n",
      "Only Mr. Lucas's actions , therefore , arose\n",
      "_pa                                        _\n",
      "tensor(1.5219, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 93\n",
      "and wet pavements , the school play-grounds ,\n",
      "_ah                                            _\n",
      "tensor(1.5129, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 94\n",
      "with pencil and straight-edge\n",
      "_the  e                       _\n",
      "tensor(1.5057, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 95\n",
      "An hour's riding brought us to a trail that\n",
      "_th                                        _\n",
      "tensor(1.6273, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 96\n",
      "obtains his musical characterisation by means\n",
      "_ao                                      _\n",
      "tensor(1.5292, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 97\n",
      "England , and returned to Rome for the winter . In late\n",
      "_to                                                _\n",
      "tensor(1.5494, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 98\n",
      "her over . She has a foot of\n",
      "_the                     _\n",
      "tensor(1.6581, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 99\n",
      "the house with a fury that disarranged\n",
      "_fhe                              _\n",
      "tensor(1.5788, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 100\n",
      "are usually more expensive than clay ones ,\n",
      "_to   e                                    _\n",
      "tensor(1.6262, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 101\n",
      "far between .\n",
      "_to        _\n",
      "tensor(1.4943, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 102\n",
      "heard of often in the newspapers -\n",
      "_toe  e                           _\n",
      "tensor(1.5693, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 103\n",
      "Centres . The former consists of representatives from\n",
      "_wh                                              _\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 104\n",
      "doorway looking more composed . In the\n",
      "_toe  e                          ee_\n",
      "tensor(1.5277, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 105\n",
      "financing the Exchequer had become stabilized .\n",
      "_toe                              e     a  an_\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 106\n",
      "personnel department or by an approach to\n",
      "_to                                         _\n",
      "tensor(1.5809, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 107\n",
      "provide our schemas , nor do we need to know as far as\n",
      "_'h                                                  _\n",
      "tensor(1.5959, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 108\n",
      "I am indifferent , but I really tremble\n",
      "_to   e                               _\n",
      "tensor(1.5124, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 109\n",
      "This was why the Labour Party did not think it right\n",
      "_Ta                                            _\n",
      "tensor(1.4802, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 110\n",
      "showing in the little town . It was\n",
      "_toe ee            e                _\n",
      "tensor(1.5093, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 111\n",
      "\" Better ask Robbie Munyard . \" \" What 's he been\n",
      "_Ti                                              _\n",
      "tensor(1.5069, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 112\n",
      "Govr. and Compa. of the Bank of England would never\n",
      "_Th             e  e                              _\n",
      "tensor(1.4569, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 113\n",
      "pulling on his gloves and adjusting his hat . ' Look , Bob , '\n",
      "_se                                                        _\n",
      "tensor(1.4950, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 114\n",
      "performed at the small theatre in the village , when new talent would\n",
      "_e  e                                          te              n_\n",
      "tensor(1.5168, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 115\n",
      "robe that each generation wears in turn -\n",
      "_the                      e   eeeeee _\n",
      "tensor(1.6808, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 116\n",
      "huh ? \"\n",
      "_to     _\n",
      "tensor(1.4789, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 117\n",
      "homoeopathy had been brought to\n",
      "_toe  e                        _\n",
      "tensor(1.4635, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 118\n",
      "over West Germany's cash offer to help\n",
      "_ao                                  _\n",
      "tensor(1.4954, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 119\n",
      "drunk and disorderly conduct .\n",
      "_aheeee    e neee      e  n   _\n",
      "tensor(1.5348, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 120\n",
      "large majority of Labour M Ps are likely to\n",
      "_to                                    _\n",
      "tensor(1.5028, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 121\n",
      "Such permanent occurrence at the surface\n",
      "_toe  e                                 _\n",
      "tensor(1.4683, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 122\n",
      "a half years ago . Nevertheless there is little\n",
      "_teet                                   e  e    _\n",
      "tensor(1.4954, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 123\n",
      "will return .\n",
      "_toe         _\n",
      "tensor(1.4230, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 124\n",
      "in places and has a line or two of painful home truths\n",
      "_wa                                               e_\n",
      "tensor(1.4461, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 125\n",
      "strong maternal instinct to the unborn child\n",
      "_soaae       oa    e       a   e           _\n",
      "tensor(1.4932, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 126\n",
      "' Good heavens , darling , why on earth\n",
      "_to                                  _\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 127\n",
      "Sir Francis Burdett described to Anglesey\n",
      "_to   e                               n_\n",
      "tensor(1.5534, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 128\n",
      "to give the system a trial , adding that it was being\n",
      "_aoa                                               _\n",
      "tensor(1.4548, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 129\n",
      "Something in Sandra's attitude struck\n",
      "_woe aa ie                            _\n",
      "tensor(1.5210, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 130\n",
      "to despair . And yet , wherever the issues were put\n",
      "_p                                                 e_\n",
      "tensor(1.5015, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 131\n",
      "mother's bedside .\n",
      "_toe te t    _\n",
      "tensor(1.5511, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 132\n",
      "on each side .\n",
      "_to     t   _\n",
      "tensor(1.4534, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 133\n",
      "widespread resentment over the U.S. Polaris base in\n",
      "_toe eeee       e  e                              ee_\n",
      "tensor(1.4932, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 134\n",
      "as regards duration of marriage and\n",
      "_a     n                           _\n",
      "tensor(1.5454, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 135\n",
      "time . Confusion of the original issue\n",
      "_woe  o                   i    i      _\n",
      "tensor(1.4593, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 136\n",
      "fascinated by the way he looked when you\n",
      "_aoeaaeeee     e                       _\n",
      "tensor(1.4164, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 137\n",
      "effective , giving full value to the formal elements\n",
      "_tia ei                                    e     t_\n",
      "tensor(1.4305, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 138\n",
      "When the sailing season was past , he sent Pearl\n",
      "_th          an e  e                            _\n",
      "tensor(1.3959, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 139\n",
      "all she could hear were Nicholas's\n",
      "_tee  e          e             e_\n",
      "tensor(1.5247, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 140\n",
      "turn down the Foot-Griffiths resolution . Mr.\n",
      "_toe  m                   s    enee          _\n",
      "tensor(1.5299, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 141\n",
      "certainly looked after his own .\n",
      "_tre ee      r ee         o    _\n",
      "tensor(1.5759, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 142\n",
      "the water has been suggested on\n",
      "_th  te    ee      e          _\n",
      "tensor(1.5605, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 143\n",
      "more than ever like a pink and gold\n",
      "_aoee   e  ee       e              _\n",
      "tensor(1.4657, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 144\n",
      "someone who knew their native villages .\n",
      "_teeueee      n  e ee     n         e e_\n",
      "tensor(1.4795, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 145\n",
      "the frame with panel pins to complete\n",
      "_tht  aann         n   a      ano e _\n",
      "tensor(1.5077, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 146\n",
      "me better than Naples . The journey has been\n",
      "_se   eeee    n   eeee         n e    e     n _\n",
      "tensor(1.4140, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 147\n",
      "Soviet Union has them .\n",
      "_tommm     o o         _\n",
      "tensor(1.4318, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 148\n",
      "peace of mind ? Philip put out\n",
      "_toree          ee e  e   n  n_\n",
      "tensor(1.4187, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 149\n",
      "do for the world Using my hand .\n",
      "_te  tr      ao   e e            _\n",
      "tensor(1.3219, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 150\n",
      "78 . Regression estimates of the expenditure on\n",
      "_J       i i        sa                      eeee_\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 151\n",
      "decided advantage of being the only\n",
      "_toeeae      a nnn               _\n",
      "tensor(1.5251, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 152\n",
      "whose presence I could almost smell ,\n",
      "_aneeee eeae  ee   e                   _\n",
      "tensor(1.4481, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 153\n",
      "from the work to ensure a good fit .\n",
      "_teu            e                    _\n",
      "tensor(1.4439, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 154\n",
      "There are several instances where he seemed unable to go\n",
      "_Thess           eee        e    e                ue     _\n",
      "tensor(1.5128, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 155\n",
      "right ! Congratulations ! And away you go into\n",
      "_aade      e  e    ee                          o_\n",
      "tensor(1.3921, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 156\n",
      "water that is blown offshore must\n",
      "_tire        i           to ttt_\n",
      "tensor(1.4963, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 157\n",
      "some 2,000 delegates , the biggest gathering since 1958\n",
      "_tee  200  0 e                                   eeg _\n",
      "tensor(1.4617, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 158\n",
      "While these may ultimately be made into a picture\n",
      "_whie   e          e eee  a e    e  eeeeeeeeeeeeee_\n",
      "tensor(1.4541, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 159\n",
      "and the latest report I have is that\n",
      "_buu         oonn         n    aa   _\n",
      "tensor(1.4041, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 160\n",
      "losses will be even greater . This does not\n",
      "_Terees       ae                          _\n",
      "tensor(1.4083, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 161\n",
      "history of Anglesey's unceasing search for an\n",
      "_toasee      raee       a        s       _\n",
      "tensor(1.4889, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 162\n",
      "unrepentance preyed upon his thoughts .\n",
      "_tneennnnnn          ni e       eeee _\n",
      "tensor(1.4836, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 163\n",
      "There is no reason whatsoever why he should reproach himself . The\n",
      "_heee           n                     ee ee     ee         e    _\n",
      "tensor(1.3914, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 164\n",
      "school-leaving age , expressed as a percentage of the\n",
      "_airercconn      eaeet e              t           _\n",
      "tensor(1.4745, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 165\n",
      "then Philip was so certain that Nicholas\n",
      "_tee  hhihi           e   e e eee        _\n",
      "tensor(1.4451, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 166\n",
      "conquer .\n",
      "_tnslle ._\n",
      "tensor(1.4461, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 167\n",
      "prices , quality and tax could be efficiently su-\n",
      "_wiie ..  sr et    e  e     ee ee e  eee     e _\n",
      "tensor(1.4216, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 168\n",
      "of mind akin to the atoms of matter ?\n",
      "_t  moo           a     a            _\n",
      "tensor(1.4318, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 169\n",
      "advise Anglesey to give the system a trial , adding\n",
      "_corc   lanlln      n                  e eeee eeee  _\n",
      "tensor(1.4076, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 170\n",
      "working out his ideas , either through the company's\n",
      "_wossee   i   eeess s   e           e   e    eee    _\n",
      "tensor(1.3444, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 171\n",
      "sequentially operated : the closing of the shutter\n",
      "_satienere a  ee     e    re      e eeeeeeeeeeeeee_\n",
      "tensor(1.3798, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 172\n",
      "I 'd marry you myself . \" Gay laughed , Doc was\n",
      "_ao  aaaye   .   ae e            a  a      a   _\n",
      "tensor(1.4390, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 173\n",
      "charming character , even-tempered and sedate ,\n",
      "_inepoad   nnonoo n.    ee ee m ee  m  ee  s    _\n",
      "tensor(1.2631, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 174\n",
      "shaving when it came on , with a flat\n",
      "_tuuunnn   a  a  a  a  a             _\n",
      "tensor(1.3837, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 175\n",
      "rigid as possible , for it is on these you will be building\n",
      "_rhgi     opaa ii            oo            i   i     uiuuiu_\n",
      "tensor(1.3569, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 176\n",
      "Centres . The former consists of representatives from\n",
      "_Miioee .      oee e   e   ee e  ei ieeeeeeetaetst_\n",
      "tensor(1.3897, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 177\n",
      "of the triangle that led to Hitler , Himmler , Hess and Goering\n",
      "_ff hh  trt  tot  gt t  o te    e  ee e eeeeee  e  e eee nna_\n",
      "tensor(1.3463, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 178\n",
      "This emphasis on the legality of the former\n",
      "_Thte hooolnnn     h  e t                   _\n",
      "tensor(1.3061, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 179\n",
      "moment in disgust . She was fully aware that Gavin\n",
      "_Doaasni    iiisssiy i        a  a    a   aaaa   _\n",
      "tensor(1.3916, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 180\n",
      "would be pleasanter if such cruel and feudal\n",
      "_tosa     ooaaa nae e    ea  e          _\n",
      "tensor(1.2638, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 181\n",
      "the People will be so great at the return of\n",
      "_to   rop e ea    o  e  e e    a  e      t   _\n",
      "tensor(1.4021, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 182\n",
      "turn down the Foot-Griffiths resolution . Mr.\n",
      "_fhes nww   hhh   e  e  io    oecoe   e     _\n",
      "tensor(1.3554, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 183\n",
      "appear to \" prop up \" an out-dated institution .\n",
      "_aurel     o   e   p      e  e            din n_\n",
      "tensor(1.3304, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 184\n",
      "the Polaris base has generated some antagonism\n",
      "_Lheesalal     ee  y       nsse eeeeeeeeennn_\n",
      "tensor(1.3581, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 185\n",
      "talks .\n",
      "_aoe      _\n",
      "tensor(1.2966, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 186\n",
      "equally indignant rejoinder .\n",
      "_truull   nuuoo         ._\n",
      "tensor(1.3938, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 187\n",
      "school was held .\n",
      "_telclll aas e  _\n",
      "tensor(1.2837, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 188\n",
      "young people aged 15-17 starting\n",
      "_Torcan   nnnna e             _\n",
      "tensor(1.3470, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 189\n",
      "Mr. Diefenbaker 36 per cent , for Mr.\n",
      "_Mn.DD..ihiklkl           n           _\n",
      "tensor(1.2735, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 190\n",
      "fore ! ' After the curry , I wanted only to go upstairs to\n",
      "_wurr ! ' ' etu eee e    re e ooo                 o      _\n",
      "tensor(1.3888, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 191\n",
      "compromise . For a brief interval\n",
      "_prmppprgin,     ee  rre    e_\n",
      "tensor(1.3385, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 192\n",
      "What happens is that the unskilled worker\n",
      "_hhhat   aemeea     e      e  e         nn_\n",
      "tensor(1.3107, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 193\n",
      "Father to drive along that quiet stretch of\n",
      "_cally       imn              eee eee  eeee_\n",
      "tensor(1.4260, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 194\n",
      "content with issuing bulletins on the dangers\n",
      "_iecitl    tto ttnont it t tt t ttttt  t aaa_\n",
      "tensor(1.3508, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 195\n",
      "to revise the course in the light of\n",
      "_the ole      h ett      e e  eeeeee_\n",
      "tensor(1.3372, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 196\n",
      "rest near tip of hook .\n",
      "_AAd               _\n",
      "tensor(1.2925, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 197\n",
      "success in France and Italy , and that\n",
      "_aiccsss  n  uass  u                  _\n",
      "tensor(1.3735, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 198\n",
      "What happens is that the unskilled worker\n",
      "_Whtat  ppeme n t          n  e        lnnn_\n",
      "tensor(1.2982, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 199\n",
      "to which her own had responded as it\n",
      "_to wwt   ho o    h hh h e neeeeee e _\n",
      "tensor(1.2680, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "Epoch 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m recognizer \u001b[39m=\u001b[39m Recognizer()\n\u001b[1;32m      2\u001b[0m \u001b[39m# generator = load_model(generator, \"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)_generator_epoch9.pt\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# generator, encoder, discriminator = load_models_of_same_batch(generator, encoder, discriminator, filename_prefix=\"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)\", epoch_number=9)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train(recognizer\u001b[39m=\u001b[39mrecognizer, \n\u001b[1;32m      6\u001b[0m               train_line_dataset\u001b[39m=\u001b[39mline_dataset_train, val_line_dataset\u001b[39m=\u001b[39mline_dataset_val, \n\u001b[1;32m      7\u001b[0m               batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, recognizer_lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m,\n\u001b[1;32m      8\u001b[0m               betas\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0.999\u001b[39m), num_epochs\u001b[39m=\u001b[39m\u001b[39m700\u001b[39m, loss_balancing_alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(recognizer, train_line_dataset, val_line_dataset, batch_size, recognizer_lr, betas, num_epochs, loss_balancing_alpha)\u001b[0m\n\u001b[1;32m     42\u001b[0m test \u001b[39m=\u001b[39m test[test\u001b[39m.\u001b[39mnonzero()]\n\u001b[1;32m     43\u001b[0m test \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([int_to_char[\u001b[39mint\u001b[39m(i)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m test])\n\u001b[0;32m---> 44\u001b[0m line_image_batch \u001b[39m=\u001b[39m line_image_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m line_text_batch \u001b[39m=\u001b[39m line_text_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     46\u001b[0m plt\u001b[39m.\u001b[39mimshow(line_image_batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7f07a657fc40> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib_inline/backend_inline.py:126\u001b[0m, in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m InlineBackend\u001b[39m.\u001b[39minstance()\u001b[39m.\u001b[39mclose_figures:\n\u001b[1;32m    124\u001b[0m     \u001b[39m# ignore the tracking, just draw and close all figures\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mreturn\u001b[39;00m show(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m         \u001b[39m# safely show traceback if in IPython, else raise\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         ip \u001b[39m=\u001b[39m get_ipython()\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         display(\n\u001b[1;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39m(obj, include\u001b[39m=\u001b[39minclude, exclude\u001b[39m=\u001b[39mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    341\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(bytes_io, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2337\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2338\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2339\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2340\u001b[0m     )\n\u001b[1;32m   2341\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2342\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/figure.py:3140\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3140\u001b[0m mimage\u001b[39m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3141\u001b[0m     renderer, \u001b[39mself\u001b[39m, artists, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppressComposite)\n\u001b[1;32m   3143\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3144\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m mimage\u001b[39m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3065\u001b[0m     renderer, \u001b[39mself\u001b[39m, artists, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39msuppressComposite)\n\u001b[1;32m   3067\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/image.py:641\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         renderer\u001b[39m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[1;32m    640\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 641\u001b[0m     im, l, b, trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_image(\n\u001b[1;32m    642\u001b[0m         renderer, renderer\u001b[39m.\u001b[39mget_image_magnification())\n\u001b[1;32m    643\u001b[0m     \u001b[39mif\u001b[39;00m im \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m         renderer\u001b[39m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/image.py:949\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    946\u001b[0m transformed_bbox \u001b[39m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[1;32m    947\u001b[0m clip \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_box() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mbbox) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_on()\n\u001b[1;32m    948\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mbbox)\n\u001b[0;32m--> 949\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_image(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A, bbox, transformed_bbox, clip,\n\u001b[1;32m    950\u001b[0m                         magnification, unsampled\u001b[39m=\u001b[39munsampled)\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/image.py:518\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    513\u001b[0m mask \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mwhere(A\u001b[39m.\u001b[39mmask, np\u001b[39m.\u001b[39mfloat32(np\u001b[39m.\u001b[39mnan), np\u001b[39m.\u001b[39mfloat32(\u001b[39m1\u001b[39m))\n\u001b[1;32m    514\u001b[0m         \u001b[39mif\u001b[39;00m A\u001b[39m.\u001b[39mmask\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m A\u001b[39m.\u001b[39mshape  \u001b[39m# nontrivial mask\u001b[39;00m\n\u001b[1;32m    515\u001b[0m         \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mones_like(A, np\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m    516\u001b[0m \u001b[39m# we always have to interpolate the mask to account for\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m# non-affine transformations\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m out_alpha \u001b[39m=\u001b[39m _resample(\u001b[39mself\u001b[39m, mask, out_shape, t, resample\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    519\u001b[0m \u001b[39mdel\u001b[39;00m mask  \u001b[39m# Make sure we don't use mask anymore!\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39m# Agg updates out_alpha in place.  If the pixel has no image\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[39m# data it will not be updated (and still be 0 as we initialized\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[39m# it), if input data that would go into that output pixel than\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m# it will be `nan`, if all the input data for a pixel is good\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[39m# it will be 1, and if there is _some_ good data in that output\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m# pixel it will be between [0, 1] (such as a rotated image).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aps360/lib/python3.11/site-packages/matplotlib/image.py:207\u001b[0m, in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m resample \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     resample \u001b[39m=\u001b[39m image_obj\u001b[39m.\u001b[39mget_resample()\n\u001b[0;32m--> 207\u001b[0m _image\u001b[39m.\u001b[39mresample(data, out, transform,\n\u001b[1;32m    208\u001b[0m                 _interpd_[interpolation],\n\u001b[1;32m    209\u001b[0m                 resample,\n\u001b[1;32m    210\u001b[0m                 alpha,\n\u001b[1;32m    211\u001b[0m                 image_obj\u001b[39m.\u001b[39mget_filternorm(),\n\u001b[1;32m    212\u001b[0m                 image_obj\u001b[39m.\u001b[39mget_filterrad())\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recognizer = Recognizer()\n",
    "# generator = load_model(generator, \"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)_generator_epoch9.pt\")\n",
    "# generator, encoder, discriminator = load_models_of_same_batch(generator, encoder, discriminator, filename_prefix=\"main_model/model_snapshots/2023-07-13_18-06-43_bs4_lr0.0002_betas(0, 0.999)\", epoch_number=9)\n",
    "\n",
    "train(recognizer=recognizer, \n",
    "              train_line_dataset=line_dataset_train, val_line_dataset=line_dataset_val, \n",
    "              batch_size=64, recognizer_lr=1e-3,\n",
    "              betas=(0, 0.999), num_epochs=700, loss_balancing_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512])\n",
      "torch.Size([32, 512])\n",
      "tensor([[0.0137, 0.0137, 0.0137,  ..., 0.0137, 0.0139, 0.0137],\n",
      "        [0.0138, 0.0138, 0.0138,  ..., 0.0138, 0.0134, 0.0138],\n",
      "        [0.0137, 0.0138, 0.0137,  ..., 0.0137, 0.0135, 0.0137],\n",
      "        ...,\n",
      "        [0.0140, 0.0140, 0.0140,  ..., 0.0139, 0.0135, 0.0139],\n",
      "        [0.0137, 0.0137, 0.0137,  ..., 0.0138, 0.0139, 0.0137],\n",
      "        [0.0137, 0.0137, 0.0137,  ..., 0.0137, 0.0138, 0.0137]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([82, 73])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = line_dataset_train[0]\n",
    "print(image.shape)\n",
    "plt.title(\"\".join([int_to_char[int(val)] for val in label[label.nonzero()]]))\n",
    "print(image.squeeze(0).shape)\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "label, \"\".join([int_to_char[int(val)] for val in label[label.nonzero()]])\n",
    "\n",
    "print(torch.softmax(recognizer(image.unsqueeze(0)), 1), torch.softmax(recognizer(image.unsqueeze(0)), 1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
