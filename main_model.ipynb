{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Model for Handwritten Text Synthesis GAN\n",
    "\n",
    "This model will consist of 4 major networks, following the general architecture of an GAN.\n",
    "\n",
    "1. Encoder: Produces an embedding that will be concatenated with the noise vector.\n",
    "2. Generator: Taking noise vector as input and the text embedding to produce an 128x2048 image.\n",
    "3. Discriminator: Trained alternating with generator input and ground-truth input, binary classification real or fake.\n",
    "4. Recognizer: Taking image as input, produce a vector representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Grayscale, Resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A|MOVE|to|stop|Mr.|Gaitskell|from|nominating'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LineData():\n",
    "    def __init__(self, image_name, image_path, height, width, graylevel_lim, transcription):\n",
    "        self.image_name = image_name\n",
    "        self.image_path = image_path\n",
    "        # Add a reason for threshold (theres bounding boxes)\n",
    "        # TODO progress report asks for statistics on the data, record this\n",
    "        # - average length, max lenth, shortest length, \n",
    "        # TODO Remember to explain: why we choose to only use lines (becaues their legnths are pretty consistent)\n",
    "        # our model doesn' thave to begin at the starts of a sentence\n",
    "        self.graylevel_lim = graylevel_lim\n",
    "        self.transcription = transcription\n",
    "\n",
    "class LineDataset(Dataset):\n",
    "    def __init__(self, lines_dir, lines_label_dir):\n",
    "        self.lines_dir = lines_dir\n",
    "        self.lines_info = []  # List containing the stuff in `lines.txt`\n",
    "\n",
    "        # Loop through `lines.txt`\n",
    "        with open(lines_label_dir, \"r\") as f:\n",
    "            i = 0\n",
    "            for line in f.readlines():\n",
    "                if line.startswith(\"#\"):\n",
    "                    continue\n",
    "\n",
    "                # Valid line, not the intro text\n",
    "                line_items = line.strip().split(\" \")  # strip() to remove newlines\n",
    "\n",
    "                # The actual items (we extract the important ones)\n",
    "                image_name = line_items[0]\n",
    "                status = line_items[1]\n",
    "                graylevel_lim = int(line_items[2])  # For binarize thresholding (actual legends for providing this)\n",
    "                transcription = line_items[-1]\n",
    "\n",
    "                # Skip error ones\n",
    "                if status == \"err\":\n",
    "                    continue\n",
    "\n",
    "                # Alphanumeric + common punctuation\n",
    "                # Returns None if no match\n",
    "                # 26 + 26 + 10 + 9 + 1 = 72\n",
    "                if re.fullmatch(\"[a-zA-Z0-9.!?'\\\",:;|-]*\", transcription) is None:\n",
    "                    continue\n",
    "\n",
    "                # Now we have a valid line\n",
    "                # And we can get the `.png` image path\n",
    "                # Assume the root is the directory for `lines/`\n",
    "                inp = image_name.split(\"-\")  # `inp` stands for image name parts\n",
    "                # TODO maybe use os.path.join\n",
    "                image_path = os.path.join(lines_dir, f\"{inp[0]}/{inp[0]}-{inp[1]}/{image_name}.png\")\n",
    "                tmp_image = read_image(image_path)  # Temporary image to get the size of it\n",
    "                _, height, width = tmp_image.shape  # width is the longer one (along x axis)\n",
    "\n",
    "                # Doing some calculations for scaling\n",
    "                factor = 128/height\n",
    "                if width * factor >= 2048:\n",
    "                    continue\n",
    "\n",
    "                # Now we have an image that can be scaled into a valid size\n",
    "\n",
    "                LineData_obj = LineData(image_name, image_path, height, width, graylevel_lim, transcription)\n",
    "                self.lines_info.append(LineData_obj)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines_info)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        LineData_obj = self.lines_info[index]\n",
    "\n",
    "        # Get the image\n",
    "        # TODO change datatype\n",
    "        image_tensor = read_image(LineData_obj.image_path)\n",
    "\n",
    "        # Grayscale the image - if the image is not already in grayscale\n",
    "        grayscale_transform = Grayscale()\n",
    "        grayscale_image = grayscale_transform(image_tensor)\n",
    "\n",
    "        # Threshold it\n",
    "        treshold_image = grayscale_image >= LineData_obj.graylevel_lim\n",
    "\n",
    "        # Resize it\n",
    "        resize_transform = Resize(128)\n",
    "        resized_image = resize_transform(treshold_image)\n",
    "\n",
    "        # Add padding\n",
    "        _, _, resized_height = resized_image.shape\n",
    "        padding_to_add = 2048 - resized_height\n",
    "        resized_image = F.pad(resized_image, (0, padding_to_add), value=1)\n",
    "        \n",
    "        # Return the image and its label\n",
    "        return resized_image.squeeze(0), LineData_obj.transcription\n",
    "\n",
    "# TODO save the tensor as a file so we do'nt have to process every time\n",
    "# saving the final processed tensor \n",
    "# use int8 as the datatype\n",
    "\n",
    "\n",
    "# TODO separate dataloader for images and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dataset = LineDataset(lines_dir=\"./data/lines/\", lines_label_dir=\"./data/lines.txt\")\n",
    "line_dataloader = DataLoader(line_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that|girl|who|said|hullo|to|him|in|the|garden|?'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = line_dataset[-1]\n",
    "plt.imshow(image, cmap='gray')\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataloading Functions\"\"\"\n",
    "\"\"\"Noise Functions\"\"\"\n",
    "\"\"\"Training Functions\"\"\"\n",
    "\"\"\"Evaluation Functions\"\"\"\n",
    "\"\"\"Plotting Functions\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: (N, C, H, W), with condition vector of shape (N, num_conditions)\n",
    "    Output: (N, C, H, W)\n",
    "\n",
    "    Conditional Batch Normalization\n",
    "    Idea obtained from https://arxiv.org/pdf/1809.11096.pdf\n",
    "    This is a network layer that applies batch normalization to the input tensor, and conditions it on a condition vector\n",
    "    For the Generator, this allows the network to learn to generate images conditioned on the class label and the noise vector\n",
    "\n",
    "    This network takes in a condition vector of length num_conditions, and applies batch normalization to the input tensor. \n",
    "    Then it computes 2 affine parameters (scale and bias) for each channel of the input tensor, conditioned on the condition vector through a linear layer.\n",
    "    The affine parameters are then applied to the input tensor, and the output is returned.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, num_conditions):\n",
    "        \"\"\"\n",
    "        in_channels: number of channels in the input tensor\n",
    "        num_conditions: length of the condition vector\n",
    "        \"\"\"\n",
    "        super(ConditionalBatchNorm2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # batch normalize the input, without using affine parameters\n",
    "        self.batch_norm = nn.BatchNorm2d(in_channels, affine=False)\n",
    "\n",
    "        # set up affine parameters conditioned on the condition vector\n",
    "        self.embed_conditions = nn.Sequential(\n",
    "            # 512 hidden units are used by https://arxiv.org/pdf/1903.00277.pdf\n",
    "            nn.Linear(num_conditions, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, in_channels * 2)\n",
    "        )\n",
    "\n",
    "        # https://arxiv.org/pdf/1809.11096.pdf\n",
    "        # initialize affine parameters to be all zeros for bias and ones for scale\n",
    "        self.embed_conditions.weight.data.zero_()\n",
    "        self.embed_conditions.bias.data[:in_channels] = 1\n",
    "\n",
    "    def forward(self, x, conditions):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (N, C, H, W)\n",
    "        conditions: condition vector of shape (N, num_conditions)\n",
    "        \"\"\"\n",
    "        # apply batch normalization, out still has shape (N, C, H, W)\n",
    "        out = self.batch_norm(x)\n",
    "\n",
    "        # compute affine parameters\n",
    "        params = self.embed_conditions(conditions)\n",
    "        # params has shape (N, 2 * C), we split the channel dimension in half into 2 tensors of shape (N, C)\n",
    "        scale, bias = params.chunk(2, dim=1)\n",
    "\n",
    "        # apply scale and bias. every channel's values are scaled and biased by the channel's own scale and bias value\n",
    "        out = scale.view(-1, self.in_channels, 1, 1) * out + bias.view(-1, self.in_channels, 1, 1)\n",
    "\n",
    "        # out has shape (N, C, H, W)\n",
    "        return out\n",
    "    \n",
    "class ResBlockUp(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: (N, in_channels, H, W), with condition vector of shape (N, num_conditions)\n",
    "    Output: (N, out_channels, H * 2, W * 2)\n",
    "\n",
    "    Residual Block for Upsampling\n",
    "    Idea obtained from https://arxiv.org/pdf/1903.00277.pdf\n",
    "    This is a network layer that upsamples the input tensor by a factor of 2, and conditions it on a condition vector\n",
    "    For the Generator, this allows the network to learn to generate images conditioned on the class label and the noise vector\n",
    "\n",
    "    This network takes in a condition vector of length num_conditions, and upsamples the input tensor by a factor of 2, accounting for the condition vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_conditions):\n",
    "        \"\"\"\n",
    "        in_channels: number of channels in the input tensor\n",
    "        out_channels: number of channels in the output tensor\n",
    "        num_conditions: length of the condition vector\n",
    "\n",
    "        specifications inspired by https://arxiv.org/pdf/1903.00277.pdf\n",
    "        \"\"\"\n",
    "        super(ResBlockUp, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.batch_norm1 = ConditionalBatchNorm2d(out_channels, num_conditions)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch_norm2 = ConditionalBatchNorm2d(out_channels, num_conditions)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        else:\n",
    "            self.conv1x1 = None\n",
    "\n",
    "    def forward(self, x, conditions):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (N, C, H, W)\n",
    "        conditions: condition vector of shape (N, num_conditions)\n",
    "        \"\"\"\n",
    "        # upsample the input tensor\n",
    "        out1 = self.upsample(x)\n",
    "        # depending on if this res_block_up changes the number of channels, we may need to use a 1x1 convolution to change the number of channels\n",
    "        if self.conv1x1 is not None:\n",
    "            out1 = self.conv1x1(out1)\n",
    "        \n",
    "        # second part of the res_block_up\n",
    "        out2 = self.batch_norm1(x, conditions)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.upsample(out2)\n",
    "        out2 = self.conv1(out2)\n",
    "        out2 = self.batch_norm2(out2, conditions)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.conv2(out2)\n",
    "        \n",
    "        # the output has shape (N, out_channels, 2 * H, 2 * W)\n",
    "        out = out1 + out2\n",
    "        return out\n",
    "    \n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO: this should be the correct implementation of self-attention, but I am not sure if it is correct. Will check later.\n",
    "    \n",
    "    A support layer for the Generator network. Used to help the Generator learn to generate images with more realistic details.\n",
    "    Idea obtained from: https://arxiv.org/pdf/1805.08318.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        # f\n",
    "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1, bias=False)\n",
    "        # g\n",
    "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1, bias=False)\n",
    "        # h\n",
    "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (N, C, H, W)\n",
    "        \"\"\"\n",
    "        # get the shape of the input tensor\n",
    "        N, C, H, W = x.size()\n",
    "\n",
    "        # get the query, key, and value tensors\n",
    "        query = self.query_conv(x).view(N, -1, H * W).permute(0, 2, 1)\n",
    "        key = self.key_conv(x).view(N, -1, H * W)\n",
    "        value = self.value_conv(x).view(N, -1, H * W)\n",
    "\n",
    "        # compute the attention map\n",
    "        attention = torch.bmm(query, key)\n",
    "        attention = self.softmax(attention)\n",
    "\n",
    "        # compute the output\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(N, C, H, W)\n",
    "        out = self.gamma * out + x\n",
    "\n",
    "        # out has shape (N, C, H, W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlockDown(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        in_channels: number of channels in the input tensor\n",
    "        out_channels: number of channels in the output tensor\n",
    "\n",
    "        specifications inspired by https://arxiv.org/pdf/1903.00277.pdf\n",
    "        \"\"\"\n",
    "        super(ResBlockDown, self).__init__()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.average_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        else:\n",
    "            self.conv1x1 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (N, C, H, W)\n",
    "        \"\"\"\n",
    "        # upsample the input tensor\n",
    "        out1 = x\n",
    "        # depending on if this res_block_down changes the number of channels, we may need to use a 1x1 convolution to change the number of channels\n",
    "        if self.conv1x1 is not None:\n",
    "            out1 = self.conv1x1(out1)\n",
    "        out1 = self.average_pool(out1)\n",
    "        \n",
    "        # second part of the res_block_up\n",
    "        out2 = self.batch_norm1(x)\n",
    "        out2 = self.leaky_relu(out2)\n",
    "        out2 = self.conv1(out2)\n",
    "        out2 = self.batch_norm2(out2)\n",
    "        out2 = self.leaky_relu(out2)\n",
    "        out2 = self.conv2(out2)\n",
    "        out2 = self.average_pool(out2)\n",
    "        \n",
    "        # the output has shape (N, out_channels, H / 2, W / 2)\n",
    "        out = out1 + out2\n",
    "        return out\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        in_channels: number of channels in the input tensor\n",
    "        out_channels: number of channels in the output tensor\n",
    "\n",
    "        specifications inspired by https://arxiv.org/pdf/1903.00277.pdf\n",
    "        \"\"\"\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        else:\n",
    "            self.conv1x1 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (N, C, H, W)\n",
    "        \"\"\"\n",
    "        # upsample the input tensor\n",
    "        out1 = x\n",
    "        # depending on if this res_block_down changes the number of channels, we may need to use a 1x1 convolution to change the number of channels\n",
    "        if self.conv1x1 is not None:\n",
    "            out1 = self.conv1x1(out1)\n",
    "        \n",
    "        # second part of the res_block_up\n",
    "        out2 = self.batch_norm1(x)\n",
    "        out2 = self.leaky_relu(out2)\n",
    "        out2 = self.conv1(out2)\n",
    "        out2 = self.batch_norm2(out2)\n",
    "        out2 = self.leaky_relu(out2)\n",
    "        out2 = self.conv2(out2)\n",
    "        \n",
    "        # the output has shape (N, out_channels, H, W)\n",
    "        out = out1 + out2\n",
    "        return out\n",
    "    \n",
    "class GlobalSumPooling(nn.Module):\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (N, C, H, W)\n",
    "\n",
    "        returns a tensor of shape (N, C)\n",
    "        \"\"\"\n",
    "        return torch.sum(x, dim=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Main Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN\n",
    "    Input with a vector representation of an ascii text\n",
    "    Output a vector embedding of the text\n",
    "    Purpose is to produce an embedding of the text that includes the relationship between the characters\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Transposed CNN\n",
    "    Input with a vector embedding of the text and a noise vector\n",
    "    Output a 128 x 2048 grayscale image\n",
    "    Purpose is to produce an image that is a representation of the text, with the noise vector adding some variation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, noise_dim, embedding_dim):\n",
    "        \"\"\" \n",
    "        noise_dim: dimension of the noise vector, should be divisible by 8\n",
    "        embedding_dim: dimension of the embedding vector\n",
    "\n",
    "        specifications inspired by https://arxiv.org/pdf/1903.00277.pdf\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # We are likely going to need to use 7 ResBlockUp layers to get the image to the desired size of 128 x 2048\n",
    "        # We will upscale to this from a 1 x 16 tensor\n",
    "        # 7 ResBlockUp also mean our noise vector will be split into 8 parts. \n",
    "        self.noise_chunk_size = noise_dim // 8\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(self.noise_chunk_size, 256 * 1 * 16)\n",
    "        self.res_block_up1 = ResBlockUp(256, 256, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.res_block_up2 = ResBlockUp(256, 128, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.res_block_up3 = ResBlockUp(128, 128, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.res_block_up4 = ResBlockUp(128, 64, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.self_attention = SelfAttention(64)\n",
    "        self.res_block_up5 = ResBlockUp(64, 32, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.res_block_up6 = ResBlockUp(32, 16, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.res_block_up7 = ResBlockUp(16, 16, self.embedding_dim + self.noise_chunk_size)\n",
    "        self.batch_norm = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, noise, embedding):\n",
    "        \"\"\"\n",
    "        noise: noise vector of shape (N, noise_dim)\n",
    "        embedding: embedding of the text of shape (N, embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        # split the noise vector into 8 parts\n",
    "        noise_chunks = torch.split(noise, self.noise_chunk_size, dim=1)\n",
    "\n",
    "        # first input to the network is the first noise chunk\n",
    "        x = noise_chunks[0]\n",
    "        # pass the concatenated tensor through the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        # reshape the tensor to have the desired shape\n",
    "        x = x.view(-1, 256, 1, 16)\n",
    "        # pass the tensor through the ResBlockUp layers\n",
    "        x = self.res_block_up1(x, torch.cat((embedding, noise_chunks[1]), dim=1))\n",
    "        x = self.res_block_up2(x, torch.cat((embedding, noise_chunks[2]), dim=1))\n",
    "        x = self.res_block_up3(x, torch.cat((embedding, noise_chunks[3]), dim=1))\n",
    "        x = self.res_block_up4(x, torch.cat((embedding, noise_chunks[4]), dim=1))\n",
    "        x = self.self_attention(x)\n",
    "        x = self.res_block_up5(x, torch.cat((embedding, noise_chunks[5]), dim=1))\n",
    "        x = self.res_block_up6(x, torch.cat((embedding, noise_chunks[6]), dim=1))\n",
    "        x = self.res_block_up7(x, torch.cat((embedding, noise_chunks[7]), dim=1))\n",
    "        # pass the tensor through the batch norm layer\n",
    "        x = self.batch_norm(x)\n",
    "        # pass the tensor through the relu layer\n",
    "        x = self.relu(x)\n",
    "        # pass the tensor through the convolution layer\n",
    "        x = self.conv(x)\n",
    "        # pass the tensor through the sigmoid\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN\n",
    "    Input with a 128 x 2048 grayscale image\n",
    "    Output a probability that the image is real and not generated\n",
    "    Purpose is to determine if the image is real or generated, to encourage the generator to produce realistic images\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" \n",
    "        noise_dim: dimension of the noise vector, should be divisible by 8\n",
    "        embedding_dim: dimension of the embedding vector\n",
    "\n",
    "        specifications inspired by https://arxiv.org/pdf/1903.00277.pdf\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.res_block_down1 = ResBlockDown(1, 16)\n",
    "        self.res_block_down2 = ResBlockDown(16, 16)\n",
    "        self.res_block_down3 = ResBlockDown(16, 32)\n",
    "        self.self_attention = SelfAttention(32)\n",
    "        self.res_block_down4 = ResBlockDown(32, 64)\n",
    "        self.res_block_down5 = ResBlockDown(64, 128)\n",
    "        self.res_block_down6 = ResBlockDown(128, 128)\n",
    "        self.res_block_down7 = ResBlockDown(128, 256)\n",
    "        self.res_block = ResBlock(256, 256)\n",
    "        self.global_sum_pooling = GlobalSumPooling()\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        # No sigmoid here, we will use BCEWithLogitsLoss instead\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        image: image tensor of shape (N, 1, 128, 2048)\n",
    "        \"\"\"\n",
    "\n",
    "        # pass the tensor through the ResBlockDown layers\n",
    "        x = self.res_block_down1(image)\n",
    "        x = self.res_block_down2(x)\n",
    "        x = self.res_block_down3(x)\n",
    "        x = self.self_attention(x)\n",
    "        x = self.res_block_down4(x)\n",
    "        x = self.res_block_down5(x)\n",
    "        x = self.res_block_down6(x)\n",
    "        x = self.res_block_down7(x)\n",
    "        # pass the tensor through the ResBlock layer\n",
    "        x = self.res_block(x)\n",
    "        # pass the tensor through the global sum pooling layer\n",
    "        x = self.global_sum_pooling(x)\n",
    "        # pass the tensor through the fully connected layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    pass\n",
    "\n",
    "class Recognizer(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN\n",
    "    Input with a 128 x 2048 grayscale image\n",
    "    Output a vector representation of the text\n",
    "    Purpose is to recognize the text from the image, to encourage the generator to produce images that are representations of the text\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: http://www.tbluche.com/files/icdar17_gnn.pdf use \"big architecture\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Hyperparameters to Tune\n",
    "- Dimension of text embedding, we can start with 128, 256, or 512 and increase it later on.\n",
    "- Dataset of training. If the model does not converge, it is likely we will have to manually select example images that have similar writing style.\n",
    "- Learning rate\n",
    "- Balancing the effect of recognizer and discriminator\n",
    "\n",
    "- Generator Networks:\n",
    "  - ResNetUp\n",
    "    - Should the bias be False? Or can it be True?\n",
    "      - conv1 probably don't, since it is batch-normalized right after\n",
    "      - but what about conv2?\n",
    "  - Conditional Batch Norm\n",
    "  - Number of filters in each resnet block\n",
    "- Discriminator Networks:\n",
    "  - ResNetDown\n",
    "    - Still if bias should be False?\n",
    "    - LeakyReLU slope\n",
    "  - ResNet\n",
    "    - bias?\n",
    "    - leakyReLU slope\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnacondaPyCharm3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
